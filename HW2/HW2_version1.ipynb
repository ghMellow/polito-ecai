{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "6791d003220b4b65956097c8a4c6f9ae",
    "deepnote_cell_type": "code",
    "execution_context_id": "f5831625-1df5-4e2f-8f38-79330cac3e8c",
    "execution_millis": 9964,
    "execution_start": 1764324392899,
    "source_hash": "6a74492e"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "from time import time\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from msc_dataset import MSCDataset\n",
    "\n",
    "# For data augmentation\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Device setup for Mac M4 Pro (MPS), CUDA (NVIDIA), or CPU fallback\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device('mps')\n",
    "elif torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "2bf1095ce3714193a5704972d8eabc47",
    "deepnote_cell_type": "code",
    "execution_context_id": "f5831625-1df5-4e2f-8f38-79330cac3e8c",
    "execution_millis": 0,
    "execution_start": 1764324402909,
    "source_hash": "2bb072ee"
   },
   "outputs": [],
   "source": [
    "# ==================== CONFIGURATION - STRATEGY 1 ====================\n",
    "# Focus: Fine-tuning esistente con miglioramenti mirati\n",
    "CFG = {\n",
    "    'sampling_rate': 16000,\n",
    "    'frame_length_in_s': 0.04,\n",
    "    'frame_step_in_s': 0.02,\n",
    "    'n_mels': 40,\n",
    "    'f_min': 20,  # Ottimizzato per voce umana\n",
    "    'f_max': 4000,\n",
    "    'seed': 42,\n",
    "    \n",
    "    # Training Parameters - MODIFICATI\n",
    "    'train_steps': 6000,  # +1000 steps per epoch (era 5000)\n",
    "    'train_batch_size': 32,  # Ridotto per better convergence (era 64)\n",
    "    'learning_rate': 0.0005,  # Ridotto per fine-tuning pi√π preciso (era 0.001)\n",
    "    'epochs': 60,  # Pi√π epochs con patience (era 50)\n",
    "    \n",
    "    # Data Augmentation - RIDOTTA per evitare overfitting\n",
    "    'time_shift_ms': 80,  # Ridotto (era 100)\n",
    "    'noise_level': 0.003,  # Ridotto (era 0.005)\n",
    "    'time_stretch_factor': 0.08,  # Ridotto (era 0.1)\n",
    "    \n",
    "    # Label Smoothing - NUOVO\n",
    "    'label_smoothing': 0.1,  # Aiuta generalizzazione\n",
    "}\n",
    "\n",
    "# Define the set of target classes\n",
    "CLASSES = ['stop', 'up']\n",
    "\n",
    "# Set Deterministic Behaviour\n",
    "torch.manual_seed(CFG['seed'])\n",
    "np.random.seed(CFG['seed'])\n",
    "random.seed(CFG['seed'])\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "ecbf3afbfac942669a020b568e53f6e7",
    "deepnote_cell_type": "code",
    "execution_context_id": "f5831625-1df5-4e2f-8f38-79330cac3e8c",
    "execution_millis": 0,
    "execution_start": 1764324402959,
    "source_hash": "ec07639e"
   },
   "outputs": [],
   "source": [
    "# ==================== MEL-SPECTROGRAM FEATURE EXTRACTOR ====================\n",
    "class MelSpectrogramExtractor(nn.Module):\n",
    "    \"\"\"ONNX-compatible Mel-Spectrogram feature extractor\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mel_transform = torchaudio.transforms.MelSpectrogram(\n",
    "            sample_rate=CFG['sampling_rate'],\n",
    "            n_fft=int(CFG['frame_length_in_s'] * CFG['sampling_rate']),\n",
    "            hop_length=int(CFG['frame_step_in_s'] * CFG['sampling_rate']),\n",
    "            n_mels=CFG['n_mels'],\n",
    "            f_min=CFG['f_min'],\n",
    "            f_max=CFG['f_max'],\n",
    "            window_fn=torch.hann_window,\n",
    "            power=2.0,\n",
    "            normalized=False,\n",
    "            center=True,\n",
    "            pad_mode=\"reflect\"\n",
    "        )\n",
    "        \n",
    "    def forward(self, waveform):\n",
    "        # waveform: (batch, samples)\n",
    "        mel_spec = self.mel_transform(waveform)  # (batch, n_mels, time)\n",
    "        \n",
    "        # Log scale\n",
    "        log_mel = torch.log(mel_spec + 1e-9)\n",
    "        \n",
    "        # Normalize to [-1, 1] range (per-sample)\n",
    "        log_mel = (log_mel - log_mel.mean(dim=[1, 2], keepdim=True)) / (log_mel.std(dim=[1, 2], keepdim=True) + 1e-9)\n",
    "        \n",
    "        return log_mel.unsqueeze(1)  # (batch, 1, n_mels, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== DATA AUGMENTATION ====================\n",
    "class AudioAugmentation:\n",
    "    \"\"\"Data augmentation per audio waveforms\"\"\"\n",
    "    def __init__(self, config, training=True):\n",
    "        self.config = config\n",
    "        self.training = training\n",
    "        \n",
    "    def time_shift(self, waveform):\n",
    "        \"\"\"Shift audio randomly in time\"\"\"\n",
    "        if not self.training or random.random() > 0.5:\n",
    "            return waveform\n",
    "            \n",
    "        shift_samples = int(random.uniform(-self.config['time_shift_ms'], \n",
    "                                          self.config['time_shift_ms']) \n",
    "                          * self.config['sampling_rate'] / 1000)\n",
    "        return torch.roll(waveform, shifts=shift_samples, dims=-1)\n",
    "    \n",
    "    def add_noise(self, waveform):\n",
    "        \"\"\"Add background white noise\"\"\"\n",
    "        if not self.training or random.random() > 0.5:\n",
    "            return waveform\n",
    "            \n",
    "        noise = torch.randn_like(waveform) * self.config['noise_level']\n",
    "        return waveform + noise\n",
    "    \n",
    "    def time_stretch(self, waveform):\n",
    "        \"\"\"Slightly speed up or slow down audio\"\"\"\n",
    "        if not self.training or random.random() > 0.5:\n",
    "            return waveform\n",
    "            \n",
    "        rate = 1.0 + random.uniform(-self.config['time_stretch_factor'], \n",
    "                                    self.config['time_stretch_factor'])\n",
    "        \n",
    "        # Simple resampling-based time stretch\n",
    "        stretched = F.interpolate(\n",
    "            waveform.unsqueeze(0), \n",
    "            size=int(waveform.shape[-1] * rate),\n",
    "            mode='linear',\n",
    "            align_corners=False\n",
    "        ).squeeze(0)\n",
    "        \n",
    "        # Pad or crop to original length\n",
    "        target_len = waveform.shape[-1]\n",
    "        if stretched.shape[-1] < target_len:\n",
    "            stretched = F.pad(stretched, (0, target_len - stretched.shape[-1]))\n",
    "        else:\n",
    "            stretched = stretched[..., :target_len]\n",
    "            \n",
    "        return stretched\n",
    "    \n",
    "    def __call__(self, waveform):\n",
    "        \"\"\"Apply all augmentations in sequence\"\"\"\n",
    "        waveform = self.time_shift(waveform)\n",
    "        waveform = self.add_noise(waveform)\n",
    "        waveform = self.time_stretch(waveform)\n",
    "        return waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "69e8d27312ad462980b748e61e3b30c5",
    "deepnote_cell_type": "code",
    "execution_context_id": "f5831625-1df5-4e2f-8f38-79330cac3e8c",
    "execution_millis": 1,
    "execution_start": 1764324403019,
    "source_hash": "688087c5"
   },
   "outputs": [],
   "source": [
    "# ==================== CNN MODEL (IMPROVED) ====================\n",
    "class KeywordSpotter(nn.Module):\n",
    "    \"\"\"Enhanced CNN for Up/Stop classification with Dropout\"\"\"\n",
    "    def __init__(self, num_classes=2, dropout=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Block 1: 1 ‚Üí 64 channels\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.dropout1 = nn.Dropout2d(dropout * 0.5)  # Light dropout early\n",
    "        \n",
    "        # Block 2: 64 ‚Üí 64 channels, downsample\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.dropout2 = nn.Dropout2d(dropout * 0.5)\n",
    "        \n",
    "        # Block 3: 64 ‚Üí 128 channels, downsample\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "        self.dropout3 = nn.Dropout2d(dropout)\n",
    "        \n",
    "        # Block 4: 128 ‚Üí 128 channels\n",
    "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        self.relu4 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # Block 5: 128 ‚Üí 256 channels (NEW)\n",
    "        self.conv5 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn5 = nn.BatchNorm2d(256)\n",
    "        self.relu5 = nn.ReLU(inplace=True)\n",
    "        self.dropout5 = nn.Dropout2d(dropout)\n",
    "        \n",
    "        # Global Average Pooling\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        # Classifier with dropout\n",
    "        self.dropout_fc = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(256, num_classes, bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: (batch, 1, 40, 49)\n",
    "        x = self.dropout1(self.relu1(self.bn1(self.conv1(x))))  # (batch, 64, 40, 49)\n",
    "        x = self.dropout2(self.relu2(self.bn2(self.conv2(x))))  # (batch, 64, 20, 25)\n",
    "        x = self.dropout3(self.relu3(self.bn3(self.conv3(x))))  # (batch, 128, 10, 13)\n",
    "        x = self.relu4(self.bn4(self.conv4(x)))                 # (batch, 128, 10, 13)\n",
    "        x = self.dropout5(self.relu5(self.bn5(self.conv5(x))))  # (batch, 256, 10, 13)\n",
    "        \n",
    "        x = self.gap(x)  # (batch, 256, 1, 1)\n",
    "        x = x.view(x.size(0), -1)  # (batch, 256)\n",
    "        x = self.dropout_fc(x)\n",
    "        x = self.fc(x)  # (batch, 2)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "921d386640ed4102b50d9506b5682916",
    "deepnote_cell_type": "code",
    "execution_context_id": "f5831625-1df5-4e2f-8f38-79330cac3e8c",
    "execution_millis": 41,
    "execution_start": 1764324403069,
    "source_hash": "5b3f3265"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "UP/STOP KEYWORD SPOTTER - STRATEGY 1 (ENHANCED)\n",
      "============================================================\n",
      "Device: mps\n",
      "Mel-Spectrogram config: n_mels=40, n_fft=640, hop=320\n",
      "Training config: epochs=60, batch_size=32, lr=0.0005\n",
      "Data Augmentation: time_shift=¬±80ms, noise=0.003, stretch=¬±8.0%\n",
      "Label Smoothing: 0.1\n",
      "============================================================\n",
      "\n",
      "üìÅ Loading datasets...\n",
      "Using data folder: ./msc-training\n",
      "Loaded 1600 samples from ./msc-training for classes ['stop', 'up']\n",
      "Using data folder: ./msc-validation\n",
      "Loaded 200 samples from ./msc-validation for classes ['stop', 'up']\n",
      "Using data folder: ./msc-testing\n",
      "Loaded 200 samples from ./msc-testing for classes ['stop', 'up']\n",
      "\n",
      "üèóÔ∏è  Initializing models...\n",
      "Model parameters: 555,330\n",
      "Estimated size (float32): 2169.26 KB\n",
      "Estimated size (int8): 542.31 KB\n"
     ]
    }
   ],
   "source": [
    "# ==================== MAIN TRAINING PIPELINE ====================\n",
    "print(\"=\" * 60)\n",
    "print(\"UP/STOP KEYWORD SPOTTER - STRATEGY 1 (ENHANCED)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Mel-Spectrogram config: n_mels={CFG['n_mels']}, n_fft={int(CFG['frame_length_in_s'] * CFG['sampling_rate'])}, hop={int(CFG['frame_step_in_s'] * CFG['sampling_rate'])}\")\n",
    "print(f\"Training config: epochs={CFG['epochs']}, batch_size={CFG['train_batch_size']}, lr={CFG['learning_rate']}\")\n",
    "print(f\"Data Augmentation: time_shift=¬±{CFG['time_shift_ms']}ms, noise={CFG['noise_level']}, stretch=¬±{CFG['time_stretch_factor']*100}%\")\n",
    "print(f\"Label Smoothing: {CFG['label_smoothing']}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create Mel-Spectrogram transform\n",
    "transform = MelSpectrogramExtractor()\n",
    "\n",
    "# Create augmentation\n",
    "train_augmentation = AudioAugmentation(CFG, training=True)\n",
    "val_augmentation = AudioAugmentation(CFG, training=False)\n",
    "\n",
    "# Create datasets\n",
    "print(\"\\nüìÅ Loading datasets...\")\n",
    "train_dataset = MSCDataset(\n",
    "    root='.',\n",
    "    classes=CLASSES,\n",
    "    split='training',\n",
    "    preprocess=None,\n",
    ")\n",
    "\n",
    "val_dataset = MSCDataset(\n",
    "    root='.',\n",
    "    classes=CLASSES,\n",
    "    split='validation',\n",
    "    preprocess=None,\n",
    ")\n",
    "\n",
    "test_dataset = MSCDataset(\n",
    "    root='.',\n",
    "    classes=CLASSES,\n",
    "    split='testing',\n",
    "    preprocess=None,\n",
    ")\n",
    "\n",
    "# Create dataloaders with RandomSampler for training\n",
    "sampler = torch.utils.data.RandomSampler(\n",
    "    train_dataset,\n",
    "    replacement=True,\n",
    "    num_samples=CFG['train_steps'] * CFG['train_batch_size'],\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CFG['train_batch_size'],\n",
    "    sampler=sampler,\n",
    "    num_workers=0,  # Set to 0 for macOS compatibility\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=100, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=100, num_workers=0)\n",
    "\n",
    "# Initialize models\n",
    "print(\"\\nüèóÔ∏è  Initializing models...\")\n",
    "feature_extractor = MelSpectrogramExtractor().to(DEVICE)\n",
    "model = KeywordSpotter(num_classes=len(CLASSES), dropout=0.3).to(DEVICE)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Model parameters: {total_params:,}\")\n",
    "print(f\"Estimated size (float32): {total_params * 4 / 1024:.2f} KB\")\n",
    "print(f\"Estimated size (int8): {total_params / 1024:.2f} KB\")\n",
    "\n",
    "# Loss with Label Smoothing and optimizer - STRATEGY 1\n",
    "loss_module = nn.CrossEntropyLoss(label_smoothing=CFG['label_smoothing'])\n",
    "optimizer = torch.optim.AdamW(  # AdamW invece di Adam\n",
    "    model.parameters(), \n",
    "    lr=CFG['learning_rate'], \n",
    "    weight_decay=2e-4,  # Aumentato (era 1e-4)\n",
    "    betas=(0.9, 0.999)\n",
    ")\n",
    "\n",
    "# Scheduler - CosineAnnealingWarmRestarts per cicli di learning rate\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optimizer, \n",
    "    T_0=10,  # Restart ogni 10 epochs\n",
    "    T_mult=2,\n",
    "    eta_min=1e-7\n",
    ")\n",
    "\n",
    "# Early stopping setup\n",
    "best_val_acc = 0\n",
    "best_val_loss = float('inf')\n",
    "patience = 20  # Pi√π patience (era 15)\n",
    "patience_counter = 0\n",
    "best_model_state = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== TRAINING & EVALUATION FUNCTIONS ====================\n",
    "\n",
    "def evaluate(model, feature_extractor, loader, device):\n",
    "    \"\"\"Evaluate model on validation/test set\"\"\"\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    total_loss = 0\n",
    "    loss_module = nn.CrossEntropyLoss()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            x = batch['x'].squeeze(1).to(device)\n",
    "            y = batch['y'].to(device)\n",
    "            features = feature_extractor(x)\n",
    "            output = model(features)\n",
    "            predictions = output.argmax(dim=1)\n",
    "            correct += (predictions == y).sum().item()\n",
    "            total += y.size(0)\n",
    "            total_loss += loss_module(output, y).item()\n",
    "    \n",
    "    accuracy = (correct / total) * 100\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    return accuracy, avg_loss\n",
    "\n",
    "\n",
    "def train_epoch(model, feature_extractor, train_loader, optimizer, loss_module, device, \n",
    "                steps_per_epoch, current_epoch, augmentation):\n",
    "    \"\"\"Train model for one epoch with data augmentation\"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    start_step = current_epoch * steps_per_epoch\n",
    "    end_step = start_step + steps_per_epoch\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    step_count = 0\n",
    "    \n",
    "    for step, batch in enumerate(train_loader):\n",
    "        if step < start_step:\n",
    "            continue\n",
    "        if step >= end_step:\n",
    "            break\n",
    "            \n",
    "        x = batch['x'].squeeze(1)  # Keep on CPU for augmentation\n",
    "        y = batch['y'].to(device)\n",
    "        \n",
    "        # Apply data augmentation on CPU\n",
    "        x_augmented = []\n",
    "        for i in range(x.shape[0]):\n",
    "            aug_sample = augmentation(x[i:i+1])\n",
    "            x_augmented.append(aug_sample)\n",
    "        x = torch.cat(x_augmented, dim=0).to(device)\n",
    "        \n",
    "        # Extract features\n",
    "        with torch.no_grad():\n",
    "            features = feature_extractor(x)\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(features)\n",
    "        loss = loss_module(output, y)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping for stability\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        step_count += 1\n",
    "        \n",
    "        if ((step + 1) % 100) == 0 or step == 0:\n",
    "            print(f'Step={step}; Training Loss={loss.item():.4f}')\n",
    "    \n",
    "    avg_epoch_loss = epoch_loss / step_count if step_count > 0 else 0\n",
    "    return avg_epoch_loss\n",
    "\n",
    "\n",
    "def test_model(model, feature_extractor, test_loader, device):\n",
    "    \"\"\"Test model on test dataset\"\"\"\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            x = batch['x'].squeeze(1).to(device)\n",
    "            y = batch['y'].to(device)\n",
    "            \n",
    "            # Extract features\n",
    "            features = feature_extractor(x)\n",
    "            \n",
    "            output = model(features)\n",
    "            predictions = output.argmax(dim=1)\n",
    "            \n",
    "            correct += (predictions == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    \n",
    "    accuracy = (correct / total) * 100\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Starting training (Strategy 1)...\n",
      "\n",
      "============================================================\n",
      "EPOCH 1/60\n",
      "============================================================\n",
      "Step=0; Training Loss=0.7232\n",
      "Step=0; Training Loss=0.7232\n",
      "Step=99; Training Loss=0.5617\n",
      "\n",
      "üìä Epoch 1 Summary:\n",
      "   Train Loss: 0.6593\n",
      "   Val Acc: 84.50%\n",
      "   Val Loss: 0.4545\n",
      "   Learning Rate: 0.000500\n",
      "‚úÖ New best model! Val Acc=84.50%\n",
      "\n",
      "============================================================\n",
      "EPOCH 2/60\n",
      "============================================================\n",
      "Step=99; Training Loss=0.5617\n",
      "\n",
      "üìä Epoch 1 Summary:\n",
      "   Train Loss: 0.6593\n",
      "   Val Acc: 84.50%\n",
      "   Val Loss: 0.4545\n",
      "   Learning Rate: 0.000500\n",
      "‚úÖ New best model! Val Acc=84.50%\n",
      "\n",
      "============================================================\n",
      "EPOCH 2/60\n",
      "============================================================\n",
      "Step=199; Training Loss=0.4531\n",
      "\n",
      "üìä Epoch 2 Summary:\n",
      "   Train Loss: 0.5477\n",
      "   Val Acc: 90.50%\n",
      "   Val Loss: 0.3107\n",
      "   Learning Rate: 0.000488\n",
      "‚úÖ New best model! Val Acc=90.50%\n",
      "\n",
      "============================================================\n",
      "EPOCH 3/60\n",
      "============================================================\n",
      "Step=199; Training Loss=0.4531\n",
      "\n",
      "üìä Epoch 2 Summary:\n",
      "   Train Loss: 0.5477\n",
      "   Val Acc: 90.50%\n",
      "   Val Loss: 0.3107\n",
      "   Learning Rate: 0.000488\n",
      "‚úÖ New best model! Val Acc=90.50%\n",
      "\n",
      "============================================================\n",
      "EPOCH 3/60\n",
      "============================================================\n",
      "Step=299; Training Loss=0.4421\n",
      "\n",
      "üìä Epoch 3 Summary:\n",
      "   Train Loss: 0.4824\n",
      "   Val Acc: 87.00%\n",
      "   Val Loss: 0.3148\n",
      "   Learning Rate: 0.000452\n",
      "‚è≥ No improvement. Patience: 1/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 4/60\n",
      "============================================================\n",
      "Step=299; Training Loss=0.4421\n",
      "\n",
      "üìä Epoch 3 Summary:\n",
      "   Train Loss: 0.4824\n",
      "   Val Acc: 87.00%\n",
      "   Val Loss: 0.3148\n",
      "   Learning Rate: 0.000452\n",
      "‚è≥ No improvement. Patience: 1/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 4/60\n",
      "============================================================\n",
      "Step=399; Training Loss=0.4538\n",
      "\n",
      "üìä Epoch 4 Summary:\n",
      "   Train Loss: 0.4349\n",
      "   Val Acc: 89.00%\n",
      "   Val Loss: 0.2732\n",
      "   Learning Rate: 0.000397\n",
      "‚è≥ No improvement. Patience: 2/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 5/60\n",
      "============================================================\n",
      "Step=399; Training Loss=0.4538\n",
      "\n",
      "üìä Epoch 4 Summary:\n",
      "   Train Loss: 0.4349\n",
      "   Val Acc: 89.00%\n",
      "   Val Loss: 0.2732\n",
      "   Learning Rate: 0.000397\n",
      "‚è≥ No improvement. Patience: 2/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 5/60\n",
      "============================================================\n",
      "Step=499; Training Loss=0.3777\n",
      "\n",
      "üìä Epoch 5 Summary:\n",
      "   Train Loss: 0.4072\n",
      "   Val Acc: 90.50%\n",
      "   Val Loss: 0.2347\n",
      "   Learning Rate: 0.000327\n",
      "‚è≥ No improvement. Patience: 3/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 6/60\n",
      "============================================================\n",
      "Step=499; Training Loss=0.3777\n",
      "\n",
      "üìä Epoch 5 Summary:\n",
      "   Train Loss: 0.4072\n",
      "   Val Acc: 90.50%\n",
      "   Val Loss: 0.2347\n",
      "   Learning Rate: 0.000327\n",
      "‚è≥ No improvement. Patience: 3/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 6/60\n",
      "============================================================\n",
      "Step=599; Training Loss=0.4528\n",
      "\n",
      "üìä Epoch 6 Summary:\n",
      "   Train Loss: 0.3958\n",
      "   Val Acc: 92.00%\n",
      "   Val Loss: 0.2221\n",
      "   Learning Rate: 0.000250\n",
      "‚úÖ New best model! Val Acc=92.00%\n",
      "\n",
      "============================================================\n",
      "EPOCH 7/60\n",
      "============================================================\n",
      "Step=599; Training Loss=0.4528\n",
      "\n",
      "üìä Epoch 6 Summary:\n",
      "   Train Loss: 0.3958\n",
      "   Val Acc: 92.00%\n",
      "   Val Loss: 0.2221\n",
      "   Learning Rate: 0.000250\n",
      "‚úÖ New best model! Val Acc=92.00%\n",
      "\n",
      "============================================================\n",
      "EPOCH 7/60\n",
      "============================================================\n",
      "Step=699; Training Loss=0.3372\n",
      "\n",
      "üìä Epoch 7 Summary:\n",
      "   Train Loss: 0.3771\n",
      "   Val Acc: 92.00%\n",
      "   Val Loss: 0.2139\n",
      "   Learning Rate: 0.000173\n",
      "‚è≥ No improvement. Patience: 1/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 8/60\n",
      "============================================================\n",
      "Step=699; Training Loss=0.3372\n",
      "\n",
      "üìä Epoch 7 Summary:\n",
      "   Train Loss: 0.3771\n",
      "   Val Acc: 92.00%\n",
      "   Val Loss: 0.2139\n",
      "   Learning Rate: 0.000173\n",
      "‚è≥ No improvement. Patience: 1/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 8/60\n",
      "============================================================\n",
      "Step=799; Training Loss=0.4470\n",
      "\n",
      "üìä Epoch 8 Summary:\n",
      "   Train Loss: 0.3684\n",
      "   Val Acc: 94.00%\n",
      "   Val Loss: 0.1909\n",
      "   Learning Rate: 0.000103\n",
      "‚úÖ New best model! Val Acc=94.00%\n",
      "\n",
      "============================================================\n",
      "EPOCH 9/60\n",
      "============================================================\n",
      "Step=799; Training Loss=0.4470\n",
      "\n",
      "üìä Epoch 8 Summary:\n",
      "   Train Loss: 0.3684\n",
      "   Val Acc: 94.00%\n",
      "   Val Loss: 0.1909\n",
      "   Learning Rate: 0.000103\n",
      "‚úÖ New best model! Val Acc=94.00%\n",
      "\n",
      "============================================================\n",
      "EPOCH 9/60\n",
      "============================================================\n",
      "Step=899; Training Loss=0.3971\n",
      "\n",
      "üìä Epoch 9 Summary:\n",
      "   Train Loss: 0.3540\n",
      "   Val Acc: 95.00%\n",
      "   Val Loss: 0.1884\n",
      "   Learning Rate: 0.000048\n",
      "‚úÖ New best model! Val Acc=95.00%\n",
      "\n",
      "============================================================\n",
      "EPOCH 10/60\n",
      "============================================================\n",
      "Step=899; Training Loss=0.3971\n",
      "\n",
      "üìä Epoch 9 Summary:\n",
      "   Train Loss: 0.3540\n",
      "   Val Acc: 95.00%\n",
      "   Val Loss: 0.1884\n",
      "   Learning Rate: 0.000048\n",
      "‚úÖ New best model! Val Acc=95.00%\n",
      "\n",
      "============================================================\n",
      "EPOCH 10/60\n",
      "============================================================\n",
      "Step=999; Training Loss=0.2888\n",
      "\n",
      "üìä Epoch 10 Summary:\n",
      "   Train Loss: 0.3509\n",
      "   Val Acc: 93.50%\n",
      "   Val Loss: 0.1814\n",
      "   Learning Rate: 0.000012\n",
      "‚è≥ No improvement. Patience: 1/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 11/60\n",
      "============================================================\n",
      "Step=999; Training Loss=0.2888\n",
      "\n",
      "üìä Epoch 10 Summary:\n",
      "   Train Loss: 0.3509\n",
      "   Val Acc: 93.50%\n",
      "   Val Loss: 0.1814\n",
      "   Learning Rate: 0.000012\n",
      "‚è≥ No improvement. Patience: 1/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 11/60\n",
      "============================================================\n",
      "Step=1099; Training Loss=0.3120\n",
      "\n",
      "üìä Epoch 11 Summary:\n",
      "   Train Loss: 0.3709\n",
      "   Val Acc: 89.00%\n",
      "   Val Loss: 0.2538\n",
      "   Learning Rate: 0.000500\n",
      "‚è≥ No improvement. Patience: 2/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 12/60\n",
      "============================================================\n",
      "Step=1099; Training Loss=0.3120\n",
      "\n",
      "üìä Epoch 11 Summary:\n",
      "   Train Loss: 0.3709\n",
      "   Val Acc: 89.00%\n",
      "   Val Loss: 0.2538\n",
      "   Learning Rate: 0.000500\n",
      "‚è≥ No improvement. Patience: 2/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 12/60\n",
      "============================================================\n",
      "Step=1199; Training Loss=0.4091\n",
      "\n",
      "üìä Epoch 12 Summary:\n",
      "   Train Loss: 0.3668\n",
      "   Val Acc: 86.50%\n",
      "   Val Loss: 0.2829\n",
      "   Learning Rate: 0.000497\n",
      "‚è≥ No improvement. Patience: 3/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 13/60\n",
      "============================================================\n",
      "Step=1199; Training Loss=0.4091\n",
      "\n",
      "üìä Epoch 12 Summary:\n",
      "   Train Loss: 0.3668\n",
      "   Val Acc: 86.50%\n",
      "   Val Loss: 0.2829\n",
      "   Learning Rate: 0.000497\n",
      "‚è≥ No improvement. Patience: 3/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 13/60\n",
      "============================================================\n",
      "Step=1299; Training Loss=0.2767\n",
      "\n",
      "üìä Epoch 13 Summary:\n",
      "   Train Loss: 0.3598\n",
      "   Val Acc: 91.50%\n",
      "   Val Loss: 0.2107\n",
      "   Learning Rate: 0.000488\n",
      "‚è≥ No improvement. Patience: 4/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 14/60\n",
      "============================================================\n",
      "Step=1299; Training Loss=0.2767\n",
      "\n",
      "üìä Epoch 13 Summary:\n",
      "   Train Loss: 0.3598\n",
      "   Val Acc: 91.50%\n",
      "   Val Loss: 0.2107\n",
      "   Learning Rate: 0.000488\n",
      "‚è≥ No improvement. Patience: 4/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 14/60\n",
      "============================================================\n",
      "Step=1399; Training Loss=0.2849\n",
      "\n",
      "üìä Epoch 14 Summary:\n",
      "   Train Loss: 0.3347\n",
      "   Val Acc: 93.50%\n",
      "   Val Loss: 0.1927\n",
      "   Learning Rate: 0.000473\n",
      "‚è≥ No improvement. Patience: 5/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 15/60\n",
      "============================================================\n",
      "Step=1399; Training Loss=0.2849\n",
      "\n",
      "üìä Epoch 14 Summary:\n",
      "   Train Loss: 0.3347\n",
      "   Val Acc: 93.50%\n",
      "   Val Loss: 0.1927\n",
      "   Learning Rate: 0.000473\n",
      "‚è≥ No improvement. Patience: 5/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 15/60\n",
      "============================================================\n",
      "Step=1499; Training Loss=0.2786\n",
      "\n",
      "üìä Epoch 15 Summary:\n",
      "   Train Loss: 0.3248\n",
      "   Val Acc: 95.00%\n",
      "   Val Loss: 0.1495\n",
      "   Learning Rate: 0.000452\n",
      "‚è≥ No improvement. Patience: 6/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 16/60\n",
      "============================================================\n",
      "Step=1499; Training Loss=0.2786\n",
      "\n",
      "üìä Epoch 15 Summary:\n",
      "   Train Loss: 0.3248\n",
      "   Val Acc: 95.00%\n",
      "   Val Loss: 0.1495\n",
      "   Learning Rate: 0.000452\n",
      "‚è≥ No improvement. Patience: 6/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 16/60\n",
      "============================================================\n",
      "Step=1599; Training Loss=0.2733\n",
      "\n",
      "üìä Epoch 16 Summary:\n",
      "   Train Loss: 0.3140\n",
      "   Val Acc: 96.00%\n",
      "   Val Loss: 0.1430\n",
      "   Learning Rate: 0.000427\n",
      "‚úÖ New best model! Val Acc=96.00%\n",
      "\n",
      "============================================================\n",
      "EPOCH 17/60\n",
      "============================================================\n",
      "Step=1599; Training Loss=0.2733\n",
      "\n",
      "üìä Epoch 16 Summary:\n",
      "   Train Loss: 0.3140\n",
      "   Val Acc: 96.00%\n",
      "   Val Loss: 0.1430\n",
      "   Learning Rate: 0.000427\n",
      "‚úÖ New best model! Val Acc=96.00%\n",
      "\n",
      "============================================================\n",
      "EPOCH 17/60\n",
      "============================================================\n",
      "Step=1699; Training Loss=0.2803\n",
      "\n",
      "üìä Epoch 17 Summary:\n",
      "   Train Loss: 0.2997\n",
      "   Val Acc: 95.50%\n",
      "   Val Loss: 0.1551\n",
      "   Learning Rate: 0.000397\n",
      "‚è≥ No improvement. Patience: 1/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 18/60\n",
      "============================================================\n",
      "Step=1699; Training Loss=0.2803\n",
      "\n",
      "üìä Epoch 17 Summary:\n",
      "   Train Loss: 0.2997\n",
      "   Val Acc: 95.50%\n",
      "   Val Loss: 0.1551\n",
      "   Learning Rate: 0.000397\n",
      "‚è≥ No improvement. Patience: 1/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 18/60\n",
      "============================================================\n",
      "Step=1799; Training Loss=0.3497\n",
      "\n",
      "üìä Epoch 18 Summary:\n",
      "   Train Loss: 0.3010\n",
      "   Val Acc: 93.50%\n",
      "   Val Loss: 0.1487\n",
      "   Learning Rate: 0.000364\n",
      "‚è≥ No improvement. Patience: 2/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 19/60\n",
      "============================================================\n",
      "Step=1799; Training Loss=0.3497\n",
      "\n",
      "üìä Epoch 18 Summary:\n",
      "   Train Loss: 0.3010\n",
      "   Val Acc: 93.50%\n",
      "   Val Loss: 0.1487\n",
      "   Learning Rate: 0.000364\n",
      "‚è≥ No improvement. Patience: 2/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 19/60\n",
      "============================================================\n",
      "Step=1899; Training Loss=0.3567\n",
      "\n",
      "üìä Epoch 19 Summary:\n",
      "   Train Loss: 0.2982\n",
      "   Val Acc: 96.00%\n",
      "   Val Loss: 0.1350\n",
      "   Learning Rate: 0.000327\n",
      "‚è≥ No improvement. Patience: 3/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 20/60\n",
      "============================================================\n",
      "Step=1899; Training Loss=0.3567\n",
      "\n",
      "üìä Epoch 19 Summary:\n",
      "   Train Loss: 0.2982\n",
      "   Val Acc: 96.00%\n",
      "   Val Loss: 0.1350\n",
      "   Learning Rate: 0.000327\n",
      "‚è≥ No improvement. Patience: 3/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 20/60\n",
      "============================================================\n",
      "Step=1999; Training Loss=0.2370\n",
      "\n",
      "üìä Epoch 20 Summary:\n",
      "   Train Loss: 0.2914\n",
      "   Val Acc: 94.50%\n",
      "   Val Loss: 0.1407\n",
      "   Learning Rate: 0.000289\n",
      "‚è≥ No improvement. Patience: 4/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 21/60\n",
      "============================================================\n",
      "Step=1999; Training Loss=0.2370\n",
      "\n",
      "üìä Epoch 20 Summary:\n",
      "   Train Loss: 0.2914\n",
      "   Val Acc: 94.50%\n",
      "   Val Loss: 0.1407\n",
      "   Learning Rate: 0.000289\n",
      "‚è≥ No improvement. Patience: 4/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 21/60\n",
      "============================================================\n",
      "Step=2099; Training Loss=0.4651\n",
      "\n",
      "üìä Epoch 21 Summary:\n",
      "   Train Loss: 0.2841\n",
      "   Val Acc: 95.00%\n",
      "   Val Loss: 0.1409\n",
      "   Learning Rate: 0.000250\n",
      "‚è≥ No improvement. Patience: 5/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 22/60\n",
      "============================================================\n",
      "Step=2099; Training Loss=0.4651\n",
      "\n",
      "üìä Epoch 21 Summary:\n",
      "   Train Loss: 0.2841\n",
      "   Val Acc: 95.00%\n",
      "   Val Loss: 0.1409\n",
      "   Learning Rate: 0.000250\n",
      "‚è≥ No improvement. Patience: 5/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 22/60\n",
      "============================================================\n",
      "Step=2199; Training Loss=0.2424\n",
      "\n",
      "üìä Epoch 22 Summary:\n",
      "   Train Loss: 0.2786\n",
      "   Val Acc: 96.00%\n",
      "   Val Loss: 0.1303\n",
      "   Learning Rate: 0.000211\n",
      "‚è≥ No improvement. Patience: 6/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 23/60\n",
      "============================================================\n",
      "Step=2199; Training Loss=0.2424\n",
      "\n",
      "üìä Epoch 22 Summary:\n",
      "   Train Loss: 0.2786\n",
      "   Val Acc: 96.00%\n",
      "   Val Loss: 0.1303\n",
      "   Learning Rate: 0.000211\n",
      "‚è≥ No improvement. Patience: 6/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 23/60\n",
      "============================================================\n",
      "Step=2299; Training Loss=0.2924\n",
      "\n",
      "üìä Epoch 23 Summary:\n",
      "   Train Loss: 0.2790\n",
      "   Val Acc: 96.00%\n",
      "   Val Loss: 0.1370\n",
      "   Learning Rate: 0.000173\n",
      "‚è≥ No improvement. Patience: 7/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 24/60\n",
      "============================================================\n",
      "Step=2299; Training Loss=0.2924\n",
      "\n",
      "üìä Epoch 23 Summary:\n",
      "   Train Loss: 0.2790\n",
      "   Val Acc: 96.00%\n",
      "   Val Loss: 0.1370\n",
      "   Learning Rate: 0.000173\n",
      "‚è≥ No improvement. Patience: 7/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 24/60\n",
      "============================================================\n",
      "Step=2399; Training Loss=0.2486\n",
      "\n",
      "üìä Epoch 24 Summary:\n",
      "   Train Loss: 0.2718\n",
      "   Val Acc: 96.00%\n",
      "   Val Loss: 0.1318\n",
      "   Learning Rate: 0.000137\n",
      "‚è≥ No improvement. Patience: 8/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 25/60\n",
      "============================================================\n",
      "Step=2399; Training Loss=0.2486\n",
      "\n",
      "üìä Epoch 24 Summary:\n",
      "   Train Loss: 0.2718\n",
      "   Val Acc: 96.00%\n",
      "   Val Loss: 0.1318\n",
      "   Learning Rate: 0.000137\n",
      "‚è≥ No improvement. Patience: 8/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 25/60\n",
      "============================================================\n",
      "Step=2499; Training Loss=0.2640\n",
      "\n",
      "üìä Epoch 25 Summary:\n",
      "   Train Loss: 0.2766\n",
      "   Val Acc: 97.00%\n",
      "   Val Loss: 0.1309\n",
      "   Learning Rate: 0.000103\n",
      "‚úÖ New best model! Val Acc=97.00%\n",
      "\n",
      "============================================================\n",
      "EPOCH 26/60\n",
      "============================================================\n",
      "Step=2499; Training Loss=0.2640\n",
      "\n",
      "üìä Epoch 25 Summary:\n",
      "   Train Loss: 0.2766\n",
      "   Val Acc: 97.00%\n",
      "   Val Loss: 0.1309\n",
      "   Learning Rate: 0.000103\n",
      "‚úÖ New best model! Val Acc=97.00%\n",
      "\n",
      "============================================================\n",
      "EPOCH 26/60\n",
      "============================================================\n",
      "Step=2599; Training Loss=0.2336\n",
      "\n",
      "üìä Epoch 26 Summary:\n",
      "   Train Loss: 0.2747\n",
      "   Val Acc: 95.50%\n",
      "   Val Loss: 0.1270\n",
      "   Learning Rate: 0.000073\n",
      "‚è≥ No improvement. Patience: 1/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 27/60\n",
      "============================================================\n",
      "Step=2599; Training Loss=0.2336\n",
      "\n",
      "üìä Epoch 26 Summary:\n",
      "   Train Loss: 0.2747\n",
      "   Val Acc: 95.50%\n",
      "   Val Loss: 0.1270\n",
      "   Learning Rate: 0.000073\n",
      "‚è≥ No improvement. Patience: 1/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 27/60\n",
      "============================================================\n",
      "Step=2699; Training Loss=0.3134\n",
      "\n",
      "üìä Epoch 27 Summary:\n",
      "   Train Loss: 0.2682\n",
      "   Val Acc: 96.50%\n",
      "   Val Loss: 0.1271\n",
      "   Learning Rate: 0.000048\n",
      "‚è≥ No improvement. Patience: 2/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 28/60\n",
      "============================================================\n",
      "Step=2699; Training Loss=0.3134\n",
      "\n",
      "üìä Epoch 27 Summary:\n",
      "   Train Loss: 0.2682\n",
      "   Val Acc: 96.50%\n",
      "   Val Loss: 0.1271\n",
      "   Learning Rate: 0.000048\n",
      "‚è≥ No improvement. Patience: 2/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 28/60\n",
      "============================================================\n",
      "Step=2799; Training Loss=0.2663\n",
      "\n",
      "üìä Epoch 28 Summary:\n",
      "   Train Loss: 0.2717\n",
      "   Val Acc: 96.00%\n",
      "   Val Loss: 0.1271\n",
      "   Learning Rate: 0.000027\n",
      "‚è≥ No improvement. Patience: 3/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 29/60\n",
      "============================================================\n",
      "Step=2799; Training Loss=0.2663\n",
      "\n",
      "üìä Epoch 28 Summary:\n",
      "   Train Loss: 0.2717\n",
      "   Val Acc: 96.00%\n",
      "   Val Loss: 0.1271\n",
      "   Learning Rate: 0.000027\n",
      "‚è≥ No improvement. Patience: 3/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 29/60\n",
      "============================================================\n",
      "Step=2899; Training Loss=0.2339\n",
      "\n",
      "üìä Epoch 29 Summary:\n",
      "   Train Loss: 0.2658\n",
      "   Val Acc: 96.00%\n",
      "   Val Loss: 0.1262\n",
      "   Learning Rate: 0.000012\n",
      "‚è≥ No improvement. Patience: 4/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 30/60\n",
      "============================================================\n",
      "Step=2899; Training Loss=0.2339\n",
      "\n",
      "üìä Epoch 29 Summary:\n",
      "   Train Loss: 0.2658\n",
      "   Val Acc: 96.00%\n",
      "   Val Loss: 0.1262\n",
      "   Learning Rate: 0.000012\n",
      "‚è≥ No improvement. Patience: 4/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 30/60\n",
      "============================================================\n",
      "Step=2999; Training Loss=0.2881\n",
      "\n",
      "üìä Epoch 30 Summary:\n",
      "   Train Loss: 0.2724\n",
      "   Val Acc: 97.00%\n",
      "   Val Loss: 0.1280\n",
      "   Learning Rate: 0.000003\n",
      "‚è≥ No improvement. Patience: 5/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 31/60\n",
      "============================================================\n",
      "Step=2999; Training Loss=0.2881\n",
      "\n",
      "üìä Epoch 30 Summary:\n",
      "   Train Loss: 0.2724\n",
      "   Val Acc: 97.00%\n",
      "   Val Loss: 0.1280\n",
      "   Learning Rate: 0.000003\n",
      "‚è≥ No improvement. Patience: 5/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 31/60\n",
      "============================================================\n",
      "Step=3099; Training Loss=0.3245\n",
      "\n",
      "üìä Epoch 31 Summary:\n",
      "   Train Loss: 0.2784\n",
      "   Val Acc: 96.50%\n",
      "   Val Loss: 0.1424\n",
      "   Learning Rate: 0.000500\n",
      "‚è≥ No improvement. Patience: 6/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 32/60\n",
      "============================================================\n",
      "Step=3099; Training Loss=0.3245\n",
      "\n",
      "üìä Epoch 31 Summary:\n",
      "   Train Loss: 0.2784\n",
      "   Val Acc: 96.50%\n",
      "   Val Loss: 0.1424\n",
      "   Learning Rate: 0.000500\n",
      "‚è≥ No improvement. Patience: 6/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 32/60\n",
      "============================================================\n",
      "Step=3199; Training Loss=0.2904\n",
      "\n",
      "üìä Epoch 32 Summary:\n",
      "   Train Loss: 0.2860\n",
      "   Val Acc: 95.50%\n",
      "   Val Loss: 0.1606\n",
      "   Learning Rate: 0.000499\n",
      "‚è≥ No improvement. Patience: 7/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 33/60\n",
      "============================================================\n",
      "Step=3199; Training Loss=0.2904\n",
      "\n",
      "üìä Epoch 32 Summary:\n",
      "   Train Loss: 0.2860\n",
      "   Val Acc: 95.50%\n",
      "   Val Loss: 0.1606\n",
      "   Learning Rate: 0.000499\n",
      "‚è≥ No improvement. Patience: 7/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 33/60\n",
      "============================================================\n",
      "Step=3299; Training Loss=0.2650\n",
      "\n",
      "üìä Epoch 33 Summary:\n",
      "   Train Loss: 0.2792\n",
      "   Val Acc: 96.00%\n",
      "   Val Loss: 0.1280\n",
      "   Learning Rate: 0.000497\n",
      "‚è≥ No improvement. Patience: 8/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 34/60\n",
      "============================================================\n",
      "Step=3299; Training Loss=0.2650\n",
      "\n",
      "üìä Epoch 33 Summary:\n",
      "   Train Loss: 0.2792\n",
      "   Val Acc: 96.00%\n",
      "   Val Loss: 0.1280\n",
      "   Learning Rate: 0.000497\n",
      "‚è≥ No improvement. Patience: 8/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 34/60\n",
      "============================================================\n",
      "Step=3399; Training Loss=0.2592\n",
      "\n",
      "üìä Epoch 34 Summary:\n",
      "   Train Loss: 0.2756\n",
      "   Val Acc: 96.00%\n",
      "   Val Loss: 0.1303\n",
      "   Learning Rate: 0.000493\n",
      "‚è≥ No improvement. Patience: 9/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 35/60\n",
      "============================================================\n",
      "Step=3399; Training Loss=0.2592\n",
      "\n",
      "üìä Epoch 34 Summary:\n",
      "   Train Loss: 0.2756\n",
      "   Val Acc: 96.00%\n",
      "   Val Loss: 0.1303\n",
      "   Learning Rate: 0.000493\n",
      "‚è≥ No improvement. Patience: 9/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 35/60\n",
      "============================================================\n",
      "Step=3499; Training Loss=0.2406\n",
      "\n",
      "üìä Epoch 35 Summary:\n",
      "   Train Loss: 0.2732\n",
      "   Val Acc: 96.00%\n",
      "   Val Loss: 0.1246\n",
      "   Learning Rate: 0.000488\n",
      "‚è≥ No improvement. Patience: 10/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 36/60\n",
      "============================================================\n",
      "Step=3499; Training Loss=0.2406\n",
      "\n",
      "üìä Epoch 35 Summary:\n",
      "   Train Loss: 0.2732\n",
      "   Val Acc: 96.00%\n",
      "   Val Loss: 0.1246\n",
      "   Learning Rate: 0.000488\n",
      "‚è≥ No improvement. Patience: 10/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 36/60\n",
      "============================================================\n",
      "Step=3599; Training Loss=0.2566\n",
      "\n",
      "üìä Epoch 36 Summary:\n",
      "   Train Loss: 0.2730\n",
      "   Val Acc: 97.00%\n",
      "   Val Loss: 0.1159\n",
      "   Learning Rate: 0.000481\n",
      "‚è≥ No improvement. Patience: 11/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 37/60\n",
      "============================================================\n",
      "Step=3599; Training Loss=0.2566\n",
      "\n",
      "üìä Epoch 36 Summary:\n",
      "   Train Loss: 0.2730\n",
      "   Val Acc: 97.00%\n",
      "   Val Loss: 0.1159\n",
      "   Learning Rate: 0.000481\n",
      "‚è≥ No improvement. Patience: 11/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 37/60\n",
      "============================================================\n",
      "Step=3699; Training Loss=0.2425\n",
      "\n",
      "üìä Epoch 37 Summary:\n",
      "   Train Loss: 0.2697\n",
      "   Val Acc: 97.50%\n",
      "   Val Loss: 0.1251\n",
      "   Learning Rate: 0.000473\n",
      "‚úÖ New best model! Val Acc=97.50%\n",
      "\n",
      "============================================================\n",
      "EPOCH 38/60\n",
      "============================================================\n",
      "Step=3699; Training Loss=0.2425\n",
      "\n",
      "üìä Epoch 37 Summary:\n",
      "   Train Loss: 0.2697\n",
      "   Val Acc: 97.50%\n",
      "   Val Loss: 0.1251\n",
      "   Learning Rate: 0.000473\n",
      "‚úÖ New best model! Val Acc=97.50%\n",
      "\n",
      "============================================================\n",
      "EPOCH 38/60\n",
      "============================================================\n",
      "Step=3799; Training Loss=0.2733\n",
      "\n",
      "üìä Epoch 38 Summary:\n",
      "   Train Loss: 0.2637\n",
      "   Val Acc: 97.00%\n",
      "   Val Loss: 0.1259\n",
      "   Learning Rate: 0.000463\n",
      "‚è≥ No improvement. Patience: 1/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 39/60\n",
      "============================================================\n",
      "Step=3799; Training Loss=0.2733\n",
      "\n",
      "üìä Epoch 38 Summary:\n",
      "   Train Loss: 0.2637\n",
      "   Val Acc: 97.00%\n",
      "   Val Loss: 0.1259\n",
      "   Learning Rate: 0.000463\n",
      "‚è≥ No improvement. Patience: 1/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 39/60\n",
      "============================================================\n",
      "Step=3899; Training Loss=0.2779\n",
      "\n",
      "üìä Epoch 39 Summary:\n",
      "   Train Loss: 0.2648\n",
      "   Val Acc: 97.00%\n",
      "   Val Loss: 0.1255\n",
      "   Learning Rate: 0.000452\n",
      "‚è≥ No improvement. Patience: 2/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 40/60\n",
      "============================================================\n",
      "Step=3899; Training Loss=0.2779\n",
      "\n",
      "üìä Epoch 39 Summary:\n",
      "   Train Loss: 0.2648\n",
      "   Val Acc: 97.00%\n",
      "   Val Loss: 0.1255\n",
      "   Learning Rate: 0.000452\n",
      "‚è≥ No improvement. Patience: 2/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 40/60\n",
      "============================================================\n",
      "Step=3999; Training Loss=0.2615\n",
      "\n",
      "üìä Epoch 40 Summary:\n",
      "   Train Loss: 0.2640\n",
      "   Val Acc: 96.50%\n",
      "   Val Loss: 0.1185\n",
      "   Learning Rate: 0.000440\n",
      "‚è≥ No improvement. Patience: 3/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 41/60\n",
      "============================================================\n",
      "Step=3999; Training Loss=0.2615\n",
      "\n",
      "üìä Epoch 40 Summary:\n",
      "   Train Loss: 0.2640\n",
      "   Val Acc: 96.50%\n",
      "   Val Loss: 0.1185\n",
      "   Learning Rate: 0.000440\n",
      "‚è≥ No improvement. Patience: 3/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 41/60\n",
      "============================================================\n",
      "Step=4099; Training Loss=0.2458\n",
      "\n",
      "üìä Epoch 41 Summary:\n",
      "   Train Loss: 0.2612\n",
      "   Val Acc: 96.00%\n",
      "   Val Loss: 0.1265\n",
      "   Learning Rate: 0.000427\n",
      "‚è≥ No improvement. Patience: 4/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 42/60\n",
      "============================================================\n",
      "Step=4099; Training Loss=0.2458\n",
      "\n",
      "üìä Epoch 41 Summary:\n",
      "   Train Loss: 0.2612\n",
      "   Val Acc: 96.00%\n",
      "   Val Loss: 0.1265\n",
      "   Learning Rate: 0.000427\n",
      "‚è≥ No improvement. Patience: 4/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 42/60\n",
      "============================================================\n",
      "Step=4199; Training Loss=0.2670\n",
      "\n",
      "üìä Epoch 42 Summary:\n",
      "   Train Loss: 0.2584\n",
      "   Val Acc: 97.50%\n",
      "   Val Loss: 0.1308\n",
      "   Learning Rate: 0.000412\n",
      "‚è≥ No improvement. Patience: 5/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 43/60\n",
      "============================================================\n",
      "Step=4199; Training Loss=0.2670\n",
      "\n",
      "üìä Epoch 42 Summary:\n",
      "   Train Loss: 0.2584\n",
      "   Val Acc: 97.50%\n",
      "   Val Loss: 0.1308\n",
      "   Learning Rate: 0.000412\n",
      "‚è≥ No improvement. Patience: 5/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 43/60\n",
      "============================================================\n",
      "Step=4299; Training Loss=0.2560\n",
      "\n",
      "üìä Epoch 43 Summary:\n",
      "   Train Loss: 0.2571\n",
      "   Val Acc: 97.50%\n",
      "   Val Loss: 0.1107\n",
      "   Learning Rate: 0.000397\n",
      "‚è≥ No improvement. Patience: 6/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 44/60\n",
      "============================================================\n",
      "Step=4299; Training Loss=0.2560\n",
      "\n",
      "üìä Epoch 43 Summary:\n",
      "   Train Loss: 0.2571\n",
      "   Val Acc: 97.50%\n",
      "   Val Loss: 0.1107\n",
      "   Learning Rate: 0.000397\n",
      "‚è≥ No improvement. Patience: 6/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 44/60\n",
      "============================================================\n",
      "Step=4399; Training Loss=0.2793\n",
      "\n",
      "üìä Epoch 44 Summary:\n",
      "   Train Loss: 0.2602\n",
      "   Val Acc: 97.00%\n",
      "   Val Loss: 0.1204\n",
      "   Learning Rate: 0.000381\n",
      "‚è≥ No improvement. Patience: 7/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 45/60\n",
      "============================================================\n",
      "Step=4399; Training Loss=0.2793\n",
      "\n",
      "üìä Epoch 44 Summary:\n",
      "   Train Loss: 0.2602\n",
      "   Val Acc: 97.00%\n",
      "   Val Loss: 0.1204\n",
      "   Learning Rate: 0.000381\n",
      "‚è≥ No improvement. Patience: 7/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 45/60\n",
      "============================================================\n",
      "Step=4499; Training Loss=0.2520\n",
      "\n",
      "üìä Epoch 45 Summary:\n",
      "   Train Loss: 0.2557\n",
      "   Val Acc: 97.50%\n",
      "   Val Loss: 0.1148\n",
      "   Learning Rate: 0.000364\n",
      "‚è≥ No improvement. Patience: 8/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 46/60\n",
      "============================================================\n",
      "Step=4499; Training Loss=0.2520\n",
      "\n",
      "üìä Epoch 45 Summary:\n",
      "   Train Loss: 0.2557\n",
      "   Val Acc: 97.50%\n",
      "   Val Loss: 0.1148\n",
      "   Learning Rate: 0.000364\n",
      "‚è≥ No improvement. Patience: 8/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 46/60\n",
      "============================================================\n",
      "Step=4599; Training Loss=0.2538\n",
      "\n",
      "üìä Epoch 46 Summary:\n",
      "   Train Loss: 0.2513\n",
      "   Val Acc: 97.50%\n",
      "   Val Loss: 0.1199\n",
      "   Learning Rate: 0.000346\n",
      "‚è≥ No improvement. Patience: 9/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 47/60\n",
      "============================================================\n",
      "Step=4599; Training Loss=0.2538\n",
      "\n",
      "üìä Epoch 46 Summary:\n",
      "   Train Loss: 0.2513\n",
      "   Val Acc: 97.50%\n",
      "   Val Loss: 0.1199\n",
      "   Learning Rate: 0.000346\n",
      "‚è≥ No improvement. Patience: 9/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 47/60\n",
      "============================================================\n",
      "Step=4699; Training Loss=0.2293\n",
      "\n",
      "üìä Epoch 47 Summary:\n",
      "   Train Loss: 0.2476\n",
      "   Val Acc: 97.50%\n",
      "   Val Loss: 0.1157\n",
      "   Learning Rate: 0.000327\n",
      "‚è≥ No improvement. Patience: 10/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 48/60\n",
      "============================================================\n",
      "Step=4699; Training Loss=0.2293\n",
      "\n",
      "üìä Epoch 47 Summary:\n",
      "   Train Loss: 0.2476\n",
      "   Val Acc: 97.50%\n",
      "   Val Loss: 0.1157\n",
      "   Learning Rate: 0.000327\n",
      "‚è≥ No improvement. Patience: 10/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 48/60\n",
      "============================================================\n",
      "Step=4799; Training Loss=0.2307\n",
      "\n",
      "üìä Epoch 48 Summary:\n",
      "   Train Loss: 0.2491\n",
      "   Val Acc: 97.50%\n",
      "   Val Loss: 0.1142\n",
      "   Learning Rate: 0.000308\n",
      "‚è≥ No improvement. Patience: 11/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 49/60\n",
      "============================================================\n",
      "Step=4799; Training Loss=0.2307\n",
      "\n",
      "üìä Epoch 48 Summary:\n",
      "   Train Loss: 0.2491\n",
      "   Val Acc: 97.50%\n",
      "   Val Loss: 0.1142\n",
      "   Learning Rate: 0.000308\n",
      "‚è≥ No improvement. Patience: 11/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 49/60\n",
      "============================================================\n",
      "Step=4899; Training Loss=0.2173\n",
      "\n",
      "üìä Epoch 49 Summary:\n",
      "   Train Loss: 0.2447\n",
      "   Val Acc: 97.00%\n",
      "   Val Loss: 0.1080\n",
      "   Learning Rate: 0.000289\n",
      "‚è≥ No improvement. Patience: 12/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 50/60\n",
      "============================================================\n",
      "Step=4899; Training Loss=0.2173\n",
      "\n",
      "üìä Epoch 49 Summary:\n",
      "   Train Loss: 0.2447\n",
      "   Val Acc: 97.00%\n",
      "   Val Loss: 0.1080\n",
      "   Learning Rate: 0.000289\n",
      "‚è≥ No improvement. Patience: 12/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 50/60\n",
      "============================================================\n",
      "Step=4999; Training Loss=0.2185\n",
      "\n",
      "üìä Epoch 50 Summary:\n",
      "   Train Loss: 0.2471\n",
      "   Val Acc: 97.50%\n",
      "   Val Loss: 0.1132\n",
      "   Learning Rate: 0.000270\n",
      "‚è≥ No improvement. Patience: 13/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 51/60\n",
      "============================================================\n",
      "Step=4999; Training Loss=0.2185\n",
      "\n",
      "üìä Epoch 50 Summary:\n",
      "   Train Loss: 0.2471\n",
      "   Val Acc: 97.50%\n",
      "   Val Loss: 0.1132\n",
      "   Learning Rate: 0.000270\n",
      "‚è≥ No improvement. Patience: 13/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 51/60\n",
      "============================================================\n",
      "Step=5099; Training Loss=0.2819\n",
      "\n",
      "üìä Epoch 51 Summary:\n",
      "   Train Loss: 0.2464\n",
      "   Val Acc: 97.00%\n",
      "   Val Loss: 0.1007\n",
      "   Learning Rate: 0.000250\n",
      "‚è≥ No improvement. Patience: 14/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 52/60\n",
      "============================================================\n",
      "Step=5099; Training Loss=0.2819\n",
      "\n",
      "üìä Epoch 51 Summary:\n",
      "   Train Loss: 0.2464\n",
      "   Val Acc: 97.00%\n",
      "   Val Loss: 0.1007\n",
      "   Learning Rate: 0.000250\n",
      "‚è≥ No improvement. Patience: 14/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 52/60\n",
      "============================================================\n",
      "Step=5199; Training Loss=0.2475\n",
      "\n",
      "üìä Epoch 52 Summary:\n",
      "   Train Loss: 0.2418\n",
      "   Val Acc: 96.50%\n",
      "   Val Loss: 0.1229\n",
      "   Learning Rate: 0.000230\n",
      "‚è≥ No improvement. Patience: 15/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 53/60\n",
      "============================================================\n",
      "Step=5199; Training Loss=0.2475\n",
      "\n",
      "üìä Epoch 52 Summary:\n",
      "   Train Loss: 0.2418\n",
      "   Val Acc: 96.50%\n",
      "   Val Loss: 0.1229\n",
      "   Learning Rate: 0.000230\n",
      "‚è≥ No improvement. Patience: 15/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 53/60\n",
      "============================================================\n",
      "Step=5299; Training Loss=0.3022\n",
      "\n",
      "üìä Epoch 53 Summary:\n",
      "   Train Loss: 0.2453\n",
      "   Val Acc: 97.00%\n",
      "   Val Loss: 0.1140\n",
      "   Learning Rate: 0.000211\n",
      "‚è≥ No improvement. Patience: 16/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 54/60\n",
      "============================================================\n",
      "Step=5299; Training Loss=0.3022\n",
      "\n",
      "üìä Epoch 53 Summary:\n",
      "   Train Loss: 0.2453\n",
      "   Val Acc: 97.00%\n",
      "   Val Loss: 0.1140\n",
      "   Learning Rate: 0.000211\n",
      "‚è≥ No improvement. Patience: 16/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 54/60\n",
      "============================================================\n",
      "Step=5399; Training Loss=0.2311\n",
      "\n",
      "üìä Epoch 54 Summary:\n",
      "   Train Loss: 0.2432\n",
      "   Val Acc: 97.00%\n",
      "   Val Loss: 0.1122\n",
      "   Learning Rate: 0.000192\n",
      "‚è≥ No improvement. Patience: 17/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 55/60\n",
      "============================================================\n",
      "Step=5399; Training Loss=0.2311\n",
      "\n",
      "üìä Epoch 54 Summary:\n",
      "   Train Loss: 0.2432\n",
      "   Val Acc: 97.00%\n",
      "   Val Loss: 0.1122\n",
      "   Learning Rate: 0.000192\n",
      "‚è≥ No improvement. Patience: 17/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 55/60\n",
      "============================================================\n",
      "Step=5499; Training Loss=0.2282\n",
      "\n",
      "üìä Epoch 55 Summary:\n",
      "   Train Loss: 0.2411\n",
      "   Val Acc: 97.50%\n",
      "   Val Loss: 0.1116\n",
      "   Learning Rate: 0.000173\n",
      "‚è≥ No improvement. Patience: 18/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 56/60\n",
      "============================================================\n",
      "Step=5499; Training Loss=0.2282\n",
      "\n",
      "üìä Epoch 55 Summary:\n",
      "   Train Loss: 0.2411\n",
      "   Val Acc: 97.50%\n",
      "   Val Loss: 0.1116\n",
      "   Learning Rate: 0.000173\n",
      "‚è≥ No improvement. Patience: 18/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 56/60\n",
      "============================================================\n",
      "Step=5599; Training Loss=0.2450\n",
      "\n",
      "üìä Epoch 56 Summary:\n",
      "   Train Loss: 0.2428\n",
      "   Val Acc: 96.50%\n",
      "   Val Loss: 0.1099\n",
      "   Learning Rate: 0.000154\n",
      "‚è≥ No improvement. Patience: 19/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 57/60\n",
      "============================================================\n",
      "Step=5599; Training Loss=0.2450\n",
      "\n",
      "üìä Epoch 56 Summary:\n",
      "   Train Loss: 0.2428\n",
      "   Val Acc: 96.50%\n",
      "   Val Loss: 0.1099\n",
      "   Learning Rate: 0.000154\n",
      "‚è≥ No improvement. Patience: 19/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 57/60\n",
      "============================================================\n",
      "Step=5699; Training Loss=0.2843\n",
      "\n",
      "üìä Epoch 57 Summary:\n",
      "   Train Loss: 0.2425\n",
      "   Val Acc: 97.00%\n",
      "   Val Loss: 0.1100\n",
      "   Learning Rate: 0.000137\n",
      "‚è≥ No improvement. Patience: 20/20\n",
      "\n",
      "üõë Early stopping at epoch 57\n",
      "\n",
      "‚úÖ Loaded best model with Val Acc=97.50%\n",
      "\n",
      "============================================================\n",
      "Training completed after 57 epochs\n",
      "Best validation accuracy: 97.50%\n",
      "============================================================\n",
      "Step=5699; Training Loss=0.2843\n",
      "\n",
      "üìä Epoch 57 Summary:\n",
      "   Train Loss: 0.2425\n",
      "   Val Acc: 97.00%\n",
      "   Val Loss: 0.1100\n",
      "   Learning Rate: 0.000137\n",
      "‚è≥ No improvement. Patience: 20/20\n",
      "\n",
      "üõë Early stopping at epoch 57\n",
      "\n",
      "‚úÖ Loaded best model with Val Acc=97.50%\n",
      "\n",
      "============================================================\n",
      "Training completed after 57 epochs\n",
      "Best validation accuracy: 97.50%\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================== TRAINING LOOP - STRATEGY 1 ====================\n",
    "print(\"\\nüöÄ Starting training (Strategy 1)...\")\n",
    "\n",
    "steps_per_epoch = len(train_loader) // CFG['epochs']\n",
    "current_epoch = 0\n",
    "\n",
    "train_history = {'epoch': [], 'train_loss': [], 'val_acc': [], 'val_loss': [], 'lr': []}\n",
    "\n",
    "for epoch in range(CFG['epochs']):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"EPOCH {epoch+1}/{CFG['epochs']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Train for one epoch\n",
    "    train_loss = train_epoch(\n",
    "        model, feature_extractor, train_loader, optimizer, loss_module, \n",
    "        DEVICE, steps_per_epoch, epoch, train_augmentation\n",
    "    )\n",
    "    \n",
    "    current_epoch += 1\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    val_acc, val_loss = evaluate(model, feature_extractor, val_loader, DEVICE)\n",
    "    \n",
    "    # Get current learning rate\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    print(f'\\nüìä Epoch {current_epoch} Summary:')\n",
    "    print(f'   Train Loss: {train_loss:.4f}')\n",
    "    print(f'   Val Acc: {val_acc:.2f}%')\n",
    "    print(f'   Val Loss: {val_loss:.4f}')\n",
    "    print(f'   Learning Rate: {current_lr:.6f}')\n",
    "    \n",
    "    # Save history\n",
    "    train_history['epoch'].append(current_epoch)\n",
    "    train_history['train_loss'].append(train_loss)\n",
    "    train_history['val_acc'].append(val_acc)\n",
    "    train_history['val_loss'].append(val_loss)\n",
    "    train_history['lr'].append(current_lr)\n",
    "    \n",
    "    # Early stopping check\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_val_loss = val_loss\n",
    "        best_model_state = model.state_dict().copy()\n",
    "        patience_counter = 0\n",
    "        print(f'‚úÖ New best model! Val Acc={val_acc:.2f}%')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f'‚è≥ No improvement. Patience: {patience_counter}/{patience}')\n",
    "    \n",
    "    if patience_counter >= patience:\n",
    "        print(f'\\nüõë Early stopping at epoch {current_epoch}')\n",
    "        break\n",
    "    \n",
    "    # CosineAnnealingWarmRestarts step (chiamato dopo ogni epoch)\n",
    "    scheduler.step()\n",
    "\n",
    "# Load best model\n",
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(f'\\n‚úÖ Loaded best model with Val Acc={best_val_acc:.2f}%')\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Training completed after {current_epoch} epochs\")\n",
    "print(f\"Best validation accuracy: {best_val_acc:.2f}%\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Evaluating model on test set...\n",
      "\n",
      "üéØ Test Accuracy: 99.00%\n",
      "‚ùå FAILED: Accuracy <= 99.4%\n"
     ]
    }
   ],
   "source": [
    "# ==================== TEST EVALUATION ====================\n",
    "print(\"\\nüìä Evaluating model on test set...\")\n",
    "\n",
    "test_accuracy = test_model(model, feature_extractor, test_loader, DEVICE)\n",
    "print(f'\\nüéØ Test Accuracy: {test_accuracy:.2f}%')\n",
    "\n",
    "if test_accuracy > 99.4:\n",
    "    print(\"‚úÖ PASSED: Accuracy > 99.4%\")\n",
    "else:\n",
    "    print(\"‚ùå FAILED: Accuracy <= 99.4%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": "99a6df57d92146afae7054ec23e004f7",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SAVING MODEL\n",
      "============================================================\n",
      "Model Timestamp: 1764415450\n",
      "\n",
      "üîÑ Moving models to CPU for ONNX export...\n",
      "\n",
      "üì¶ Exporting Feature Extractor to ONNX...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1129 12:24:10.481000 38428 torch/onnx/_internal/exporter/_registration.py:107] torchvision is not installed. Skipping torchvision::nms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `MelSpectrogramExtractor([...]` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `MelSpectrogramExtractor([...]` with `torch.export.export(..., strict=False)`... ‚úÖ\n",
      "[torch.onnx] Run decomposition...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1129 12:24:10.965000 38428 torch/onnx/_internal/exporter/_registration.py:107] torchvision is not installed. Skipping torchvision::nms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Run decomposition... ‚úÖ\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ‚úÖ\n",
      "Applied 4 of general pattern rewrite rules.\n",
      "‚úÖ Feature extractor saved: ./saved_models//1764415450_frontend.onnx\n",
      "\n",
      "üì¶ Exporting Model to ONNX...\n",
      "[torch.onnx] Obtain model graph for `KeywordSpotter([...]` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `KeywordSpotter([...]` with `torch.export.export(..., strict=False)`... ‚úÖ\n",
      "[torch.onnx] Run decomposition...\n",
      "[torch.onnx] Run decomposition... ‚úÖ\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ‚úÖ\n",
      "Applied 10 of general pattern rewrite rules.\n",
      "‚úÖ Model saved: ./saved_models//1764415450_model.onnx\n",
      "\n",
      "============================================================\n",
      "SIZE REPORT (ONNX - Float32)\n",
      "============================================================\n",
      "Feature Extractor: 332.49 KB\n",
      "Model: 2178.31 KB\n",
      "Total: 2510.80 KB\n",
      "‚ö†Ô∏è  WARNING: Size > 300 KB - quantization required!\n",
      "\n",
      "üìù Saving hyperparameters and results...\n",
      "‚úÖ Results saved to ./keyword_spotter_results.csv\n",
      "\n",
      "============================================================\n",
      "TRAINING COMPLETE\n",
      "============================================================\n",
      "[torch.onnx] Obtain model graph for `KeywordSpotter([...]` with `torch.export.export(..., strict=False)`... ‚úÖ\n",
      "[torch.onnx] Run decomposition...\n",
      "[torch.onnx] Run decomposition... ‚úÖ\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ‚úÖ\n",
      "Applied 10 of general pattern rewrite rules.\n",
      "‚úÖ Model saved: ./saved_models//1764415450_model.onnx\n",
      "\n",
      "============================================================\n",
      "SIZE REPORT (ONNX - Float32)\n",
      "============================================================\n",
      "Feature Extractor: 332.49 KB\n",
      "Model: 2178.31 KB\n",
      "Total: 2510.80 KB\n",
      "‚ö†Ô∏è  WARNING: Size > 300 KB - quantization required!\n",
      "\n",
      "üìù Saving hyperparameters and results...\n",
      "‚úÖ Results saved to ./keyword_spotter_results.csv\n",
      "\n",
      "============================================================\n",
      "TRAINING COMPLETE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================== SAVE MODEL ====================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SAVING MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "timestamp = int(time())\n",
    "saved_model_dir = './saved_models/'\n",
    "if not os.path.exists(saved_model_dir):\n",
    "    os.makedirs(saved_model_dir)\n",
    "\n",
    "print(f'Model Timestamp: {timestamp}')\n",
    "\n",
    "model.eval()\n",
    "feature_extractor.eval()\n",
    "\n",
    "# Move models to CPU for ONNX export (MPS not supported for export)\n",
    "print(\"\\nüîÑ Moving models to CPU for ONNX export...\")\n",
    "model_cpu = model.cpu()\n",
    "feature_extractor_cpu = feature_extractor.cpu()\n",
    "\n",
    "# Export Feature Extractor to ONNX\n",
    "print(\"\\nüì¶ Exporting Feature Extractor to ONNX...\")\n",
    "torch.onnx.export(\n",
    "    feature_extractor_cpu,  # model to export\n",
    "    torch.randn(1, 16000),  # inputs of the model (waveform)\n",
    "    f'{saved_model_dir}/{timestamp}_frontend.onnx',  # filename of the ONNX model\n",
    "    input_names=['input'],  # input name in the ONNX model\n",
    "    dynamo=True,\n",
    "    optimize=True,\n",
    "    report=False,\n",
    "    external_data=False,\n",
    ")\n",
    "print(f\"‚úÖ Feature extractor saved: {saved_model_dir}/{timestamp}_frontend.onnx\")\n",
    "\n",
    "# Export Model to ONNX\n",
    "print(\"\\nüì¶ Exporting Model to ONNX...\")\n",
    "# Get a sample waveform from training dataset and extract features\n",
    "sample_waveform = train_dataset[0]['x'].squeeze(0).unsqueeze(0).cpu()  # (1, 16000)\n",
    "sample_features = feature_extractor_cpu(sample_waveform)  # (1, 1, n_mels, time)\n",
    "torch.onnx.export(\n",
    "    model_cpu,  # model to export\n",
    "    sample_features,  # inputs of the model (mel-spectrogram features)\n",
    "    f'{saved_model_dir}/{timestamp}_model.onnx',  # filename of the ONNX model\n",
    "    input_names=['input'],  # input name in the ONNX model\n",
    "    dynamo=True,\n",
    "    optimize=True,\n",
    "    report=False,\n",
    "    external_data=False,\n",
    ")\n",
    "print(f\"‚úÖ Model saved: {saved_model_dir}/{timestamp}_model.onnx\")\n",
    "\n",
    "# Check sizes\n",
    "fe_size = os.path.getsize(f'{saved_model_dir}/{timestamp}_frontend.onnx') / 1024\n",
    "model_size = os.path.getsize(f'{saved_model_dir}/{timestamp}_model.onnx') / 1024\n",
    "total_size = fe_size + model_size\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SIZE REPORT (ONNX - Float32)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Feature Extractor: {fe_size:.2f} KB\")\n",
    "print(f\"Model: {model_size:.2f} KB\")\n",
    "print(f\"Total: {total_size:.2f} KB\")\n",
    "\n",
    "if total_size < 300:\n",
    "    print(\"‚úÖ PASSED: Total size < 300 KB (before quantization)\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  WARNING: Size > 300 KB - quantization required!\")\n",
    "\n",
    "# Save Hyperparameters & Results\n",
    "print(\"\\nüìù Saving hyperparameters and results...\")\n",
    "output_dict = {\n",
    "    'timestamp': timestamp,\n",
    "    **CFG,\n",
    "    'test_accuracy': test_accuracy\n",
    "}\n",
    "\n",
    "df = pd.DataFrame([output_dict])\n",
    "output_path = './keyword_spotter_results.csv'\n",
    "df.to_csv(output_path, mode='a', header=not os.path.exists(output_path), index=False)\n",
    "print(f\"‚úÖ Results saved to {output_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(\"=\"*60)\n"
   ]
  }
 ],
 "metadata": {
  "deepnote_notebook_id": "c0fbadf4c9c044908423f738834a5ee0",
  "kernelspec": {
   "display_name": "hw2-Xe6H3gEB-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
