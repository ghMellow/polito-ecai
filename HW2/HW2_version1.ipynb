{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "6791d003220b4b65956097c8a4c6f9ae",
    "deepnote_cell_type": "code",
    "execution_context_id": "f5831625-1df5-4e2f-8f38-79330cac3e8c",
    "execution_millis": 9964,
    "execution_start": 1764324392899,
    "source_hash": "6a74492e"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "from time import time\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from msc_dataset import MSCDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Device setup for Mac M4 Pro (MPS), CUDA (NVIDIA), or CPU fallback\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device('mps')\n",
    "elif torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "2bf1095ce3714193a5704972d8eabc47",
    "deepnote_cell_type": "code",
    "execution_context_id": "f5831625-1df5-4e2f-8f38-79330cac3e8c",
    "execution_millis": 0,
    "execution_start": 1764324402909,
    "source_hash": "2bb072ee"
   },
   "outputs": [],
   "source": [
    "# ==================== CONFIGURATION ====================\n",
    "# CFG = {\n",
    "#     'sampling_rate': 16000,\n",
    "#     'frame_length_in_s': 0.04,\n",
    "#     'frame_step_in_s': 0.02,\n",
    "#     'n_mels': 40,\n",
    "#     'f_min': 0,\n",
    "#     'f_max': 8000,\n",
    "#     'seed': 0,\n",
    "#     'train_steps': 2000,\n",
    "#     'train_batch_size': 128,\n",
    "#     'learning_rate': 0.001,\n",
    "#     'epochs': 10,\n",
    "# }\n",
    "CFG = {\n",
    "    'sampling_rate': 16000,\n",
    "    'frame_length_in_s': 0.04,\n",
    "    'frame_step_in_s': 0.02,\n",
    "    'n_mels': 40,\n",
    "    'f_min': 80,  # ‚Üê CAMBIA\n",
    "    'f_max': 4000,  # ‚Üê CAMBIA\n",
    "    'seed': 0,\n",
    "    'train_steps': 4000,  # ‚Üê CAMBIA\n",
    "    'train_batch_size': 128,\n",
    "    'learning_rate': 0.001,\n",
    "    'epochs': 25,  # ‚Üê CAMBIA\n",
    "}\n",
    "\n",
    "# Define the set of target classes\n",
    "CLASSES = ['stop', 'up']\n",
    "\n",
    "# Set Deterministic Behaviour\n",
    "torch.manual_seed(CFG['seed'])\n",
    "np.random.seed(CFG['seed'])\n",
    "random.seed(CFG['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": "ecbf3afbfac942669a020b568e53f6e7",
    "deepnote_cell_type": "code",
    "execution_context_id": "f5831625-1df5-4e2f-8f38-79330cac3e8c",
    "execution_millis": 0,
    "execution_start": 1764324402959,
    "source_hash": "ec07639e"
   },
   "outputs": [],
   "source": [
    "# ==================== MEL-SPECTROGRAM FEATURE EXTRACTOR ====================\n",
    "class MelSpectrogramExtractor(nn.Module):\n",
    "    \"\"\"ONNX-compatible Mel-Spectrogram feature extractor\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mel_transform = torchaudio.transforms.MelSpectrogram(\n",
    "            sample_rate=CFG['sampling_rate'],\n",
    "            n_fft=int(CFG['frame_length_in_s'] * CFG['sampling_rate']),\n",
    "            hop_length=int(CFG['frame_step_in_s'] * CFG['sampling_rate']),\n",
    "            n_mels=CFG['n_mels'],\n",
    "            f_min=CFG['f_min'],\n",
    "            f_max=CFG['f_max'],\n",
    "            window_fn=torch.hann_window,\n",
    "            power=2.0,\n",
    "            normalized=False,\n",
    "            center=True,\n",
    "            pad_mode=\"reflect\"\n",
    "        )\n",
    "        \n",
    "    def forward(self, waveform):\n",
    "        # waveform: (batch, samples)\n",
    "        mel_spec = self.mel_transform(waveform)  # (batch, n_mels, time)\n",
    "        \n",
    "        # Log scale\n",
    "        log_mel = torch.log(mel_spec + 1e-9)\n",
    "        \n",
    "        # Normalize to [-1, 1] range (per-sample)\n",
    "        log_mel = (log_mel - log_mel.mean(dim=[1, 2], keepdim=True)) / (log_mel.std(dim=[1, 2], keepdim=True) + 1e-9)\n",
    "        \n",
    "        return log_mel.unsqueeze(1)  # (batch, 1, n_mels, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": "69e8d27312ad462980b748e61e3b30c5",
    "deepnote_cell_type": "code",
    "execution_context_id": "f5831625-1df5-4e2f-8f38-79330cac3e8c",
    "execution_millis": 1,
    "execution_start": 1764324403019,
    "source_hash": "688087c5"
   },
   "outputs": [],
   "source": [
    "# ==================== CNN MODEL ====================\n",
    "class KeywordSpotter(nn.Module):\n",
    "    \"\"\"Optimized CNN for Up/Stop classification\"\"\"\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Block 1: 1 ‚Üí 64 channels\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # Block 2: 64 ‚Üí 64 channels, downsample\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # Block 3: 64 ‚Üí 128 channels, downsample\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # Block 4: 128 ‚Üí 128 channels\n",
    "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        self.relu4 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # Global Average Pooling\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        # Classifier\n",
    "        self.fc = nn.Linear(128, num_classes, bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: (batch, 1, 40, 49)\n",
    "        x = self.relu1(self.bn1(self.conv1(x)))  # (batch, 64, 40, 49)\n",
    "        x = self.relu2(self.bn2(self.conv2(x)))  # (batch, 64, 20, 25)\n",
    "        x = self.relu3(self.bn3(self.conv3(x)))  # (batch, 128, 10, 13)\n",
    "        x = self.relu4(self.bn4(self.conv4(x)))  # (batch, 128, 10, 13)\n",
    "        \n",
    "        x = self.gap(x)  # (batch, 128, 1, 1)\n",
    "        x = x.view(x.size(0), -1)  # (batch, 128)\n",
    "        x = self.fc(x)  # (batch, 2)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "921d386640ed4102b50d9506b5682916",
    "deepnote_cell_type": "code",
    "execution_context_id": "f5831625-1df5-4e2f-8f38-79330cac3e8c",
    "execution_millis": 41,
    "execution_start": 1764324403069,
    "source_hash": "5b3f3265"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "UP/STOP KEYWORD SPOTTER - TRAINING PIPELINE\n",
      "============================================================\n",
      "Device: mps\n",
      "Mel-Spectrogram config: n_mels=40, n_fft=640, hop=320\n",
      "Training config: epochs=25, batch_size=128, lr=0.001\n",
      "============================================================\n",
      "\n",
      "üìÅ Loading datasets...\n",
      "Using data folder: ./msc-training\n",
      "Loaded 1600 samples from ./msc-training for classes ['stop', 'up']\n",
      "Using data folder: ./msc-validation\n",
      "Loaded 200 samples from ./msc-validation for classes ['stop', 'up']\n",
      "Using data folder: ./msc-testing\n",
      "Loaded 200 samples from ./msc-testing for classes ['stop', 'up']\n",
      "\n",
      "üèóÔ∏è  Initializing models...\n",
      "Model parameters: 259,650\n",
      "Estimated size (float32): 1014.26 KB\n",
      "Estimated size (int8): 253.56 KB\n",
      "\n",
      "üöÄ Starting training...\n",
      "Step=0; Training Loss=0.670\n",
      "Step=99; Training Loss=0.161\n",
      "Step=99; Training Loss=0.161\n",
      "\n",
      "üìä Epoch 1: Val Acc=75.00%, Val Loss=0.6960\n",
      "‚úÖ New best model! Val Acc=75.00%\n",
      "\n",
      "üìä Epoch 1: Val Acc=75.00%, Val Loss=0.6960\n",
      "‚úÖ New best model! Val Acc=75.00%\n",
      "Step=199; Training Loss=0.049\n",
      "Step=199; Training Loss=0.049\n",
      "Step=299; Training Loss=0.035\n",
      "Step=299; Training Loss=0.035\n",
      "\n",
      "üìä Epoch 2: Val Acc=90.00%, Val Loss=0.2278\n",
      "‚úÖ New best model! Val Acc=90.00%\n",
      "\n",
      "üìä Epoch 2: Val Acc=90.00%, Val Loss=0.2278\n",
      "‚úÖ New best model! Val Acc=90.00%\n",
      "Step=399; Training Loss=0.004\n",
      "Step=399; Training Loss=0.004\n",
      "\n",
      "üìä Epoch 3: Val Acc=90.00%, Val Loss=0.2899\n",
      "‚ö†Ô∏è  No improvement. Patience: 1/10\n",
      "\n",
      "üìä Epoch 3: Val Acc=90.00%, Val Loss=0.2899\n",
      "‚ö†Ô∏è  No improvement. Patience: 1/10\n",
      "Step=499; Training Loss=0.013\n",
      "Step=499; Training Loss=0.013\n",
      "Step=599; Training Loss=0.013\n",
      "Step=599; Training Loss=0.013\n",
      "\n",
      "üìä Epoch 4: Val Acc=78.00%, Val Loss=0.6729\n",
      "‚ö†Ô∏è  No improvement. Patience: 2/10\n",
      "\n",
      "üìä Epoch 4: Val Acc=78.00%, Val Loss=0.6729\n",
      "‚ö†Ô∏è  No improvement. Patience: 2/10\n",
      "Step=699; Training Loss=0.006\n",
      "Step=699; Training Loss=0.006\n",
      "Step=799; Training Loss=0.001\n",
      "\n",
      "üìä Epoch 5: Val Acc=93.50%, Val Loss=0.2157\n",
      "‚úÖ New best model! Val Acc=93.50%\n",
      "Step=799; Training Loss=0.001\n",
      "\n",
      "üìä Epoch 5: Val Acc=93.50%, Val Loss=0.2157\n",
      "‚úÖ New best model! Val Acc=93.50%\n",
      "Step=899; Training Loss=0.001\n",
      "Step=899; Training Loss=0.001\n",
      "\n",
      "üìä Epoch 6: Val Acc=93.00%, Val Loss=0.2292\n",
      "‚ö†Ô∏è  No improvement. Patience: 1/10\n",
      "\n",
      "üìä Epoch 6: Val Acc=93.00%, Val Loss=0.2292\n",
      "‚ö†Ô∏è  No improvement. Patience: 1/10\n",
      "Step=999; Training Loss=0.000\n",
      "Step=999; Training Loss=0.000\n",
      "Step=1099; Training Loss=0.000\n",
      "Step=1099; Training Loss=0.000\n",
      "\n",
      "üìä Epoch 7: Val Acc=93.00%, Val Loss=0.2322\n",
      "‚ö†Ô∏è  No improvement. Patience: 2/10\n",
      "\n",
      "üìä Epoch 7: Val Acc=93.00%, Val Loss=0.2322\n",
      "‚ö†Ô∏è  No improvement. Patience: 2/10\n",
      "Step=1199; Training Loss=0.000\n",
      "Step=1199; Training Loss=0.000\n",
      "\n",
      "üìä Epoch 8: Val Acc=93.00%, Val Loss=0.2340\n",
      "‚ö†Ô∏è  No improvement. Patience: 3/10\n",
      "\n",
      "üìä Epoch 8: Val Acc=93.00%, Val Loss=0.2340\n",
      "‚ö†Ô∏è  No improvement. Patience: 3/10\n",
      "Step=1299; Training Loss=0.000\n",
      "Step=1299; Training Loss=0.000\n",
      "Step=1399; Training Loss=0.002\n",
      "Step=1399; Training Loss=0.002\n",
      "\n",
      "üìä Epoch 9: Val Acc=92.50%, Val Loss=0.2402\n",
      "‚ö†Ô∏è  No improvement. Patience: 4/10\n",
      "\n",
      "üìä Epoch 9: Val Acc=92.50%, Val Loss=0.2402\n",
      "‚ö†Ô∏è  No improvement. Patience: 4/10\n",
      "Step=1499; Training Loss=0.000\n",
      "Step=1499; Training Loss=0.000\n",
      "Step=1599; Training Loss=0.000\n",
      "\n",
      "üìä Epoch 10: Val Acc=93.00%, Val Loss=0.2408\n",
      "‚ö†Ô∏è  No improvement. Patience: 5/10\n",
      "Step=1599; Training Loss=0.000\n",
      "\n",
      "üìä Epoch 10: Val Acc=93.00%, Val Loss=0.2408\n",
      "‚ö†Ô∏è  No improvement. Patience: 5/10\n",
      "Step=1699; Training Loss=0.000\n",
      "Step=1699; Training Loss=0.000\n",
      "\n",
      "üìä Epoch 11: Val Acc=93.00%, Val Loss=0.2454\n",
      "‚ö†Ô∏è  No improvement. Patience: 6/10\n",
      "\n",
      "üìä Epoch 11: Val Acc=93.00%, Val Loss=0.2454\n",
      "‚ö†Ô∏è  No improvement. Patience: 6/10\n",
      "Step=1799; Training Loss=0.000\n",
      "Step=1799; Training Loss=0.000\n",
      "Step=1899; Training Loss=0.000\n",
      "Step=1899; Training Loss=0.000\n",
      "\n",
      "üìä Epoch 12: Val Acc=93.00%, Val Loss=0.2423\n",
      "‚ö†Ô∏è  No improvement. Patience: 7/10\n",
      "\n",
      "üìä Epoch 12: Val Acc=93.00%, Val Loss=0.2423\n",
      "‚ö†Ô∏è  No improvement. Patience: 7/10\n",
      "Step=1999; Training Loss=0.000\n",
      "Step=1999; Training Loss=0.000\n",
      "\n",
      "üìä Epoch 13: Val Acc=92.50%, Val Loss=0.2406\n",
      "‚ö†Ô∏è  No improvement. Patience: 8/10\n",
      "\n",
      "üìä Epoch 13: Val Acc=92.50%, Val Loss=0.2406\n",
      "‚ö†Ô∏è  No improvement. Patience: 8/10\n",
      "Step=2099; Training Loss=0.000\n",
      "Step=2099; Training Loss=0.000\n",
      "Step=2199; Training Loss=0.000\n",
      "Step=2199; Training Loss=0.000\n",
      "\n",
      "üìä Epoch 14: Val Acc=93.00%, Val Loss=0.2425\n",
      "‚ö†Ô∏è  No improvement. Patience: 9/10\n",
      "\n",
      "üìä Epoch 14: Val Acc=93.00%, Val Loss=0.2425\n",
      "‚ö†Ô∏è  No improvement. Patience: 9/10\n",
      "Step=2299; Training Loss=0.000\n",
      "Step=2299; Training Loss=0.000\n",
      "Step=2399; Training Loss=0.000\n",
      "\n",
      "üìä Epoch 15: Val Acc=93.50%, Val Loss=0.2396\n",
      "‚ö†Ô∏è  No improvement. Patience: 10/10\n",
      "\n",
      "üõë Early stopping at epoch 15\n",
      "\n",
      "‚úÖ Loaded best model with Val Acc=93.50%\n",
      "\n",
      "üìä Evaluating model on test set...\n",
      "\n",
      "üéØ Test Accuracy: 97.00%\n",
      "‚ùå FAILED: Accuracy <= 99.4%\n",
      "Step=2399; Training Loss=0.000\n",
      "\n",
      "üìä Epoch 15: Val Acc=93.50%, Val Loss=0.2396\n",
      "‚ö†Ô∏è  No improvement. Patience: 10/10\n",
      "\n",
      "üõë Early stopping at epoch 15\n",
      "\n",
      "‚úÖ Loaded best model with Val Acc=93.50%\n",
      "\n",
      "üìä Evaluating model on test set...\n",
      "\n",
      "üéØ Test Accuracy: 97.00%\n",
      "‚ùå FAILED: Accuracy <= 99.4%\n"
     ]
    }
   ],
   "source": [
    "# ==================== MAIN TRAINING PIPELINE ====================\n",
    "print(\"=\" * 60)\n",
    "print(\"UP/STOP KEYWORD SPOTTER - TRAINING PIPELINE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Mel-Spectrogram config: n_mels={CFG['n_mels']}, n_fft={int(CFG['frame_length_in_s'] * CFG['sampling_rate'])}, hop={int(CFG['frame_step_in_s'] * CFG['sampling_rate'])}\")\n",
    "print(f\"Training config: epochs={CFG['epochs']}, batch_size={CFG['train_batch_size']}, lr={CFG['learning_rate']}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create Mel-Spectrogram transform\n",
    "transform = MelSpectrogramExtractor()\n",
    "\n",
    "# Create datasets\n",
    "print(\"\\nüìÅ Loading datasets...\")\n",
    "train_dataset = MSCDataset(\n",
    "    root='.',\n",
    "    classes=CLASSES,\n",
    "    split='training',\n",
    "    preprocess=None,\n",
    ")\n",
    "\n",
    "val_dataset = MSCDataset(\n",
    "    root='.',\n",
    "    classes=CLASSES,\n",
    "    split='validation',\n",
    "    preprocess=None,\n",
    ")\n",
    "\n",
    "test_dataset = MSCDataset(\n",
    "    root='.',\n",
    "    classes=CLASSES,\n",
    "    split='testing',\n",
    "    preprocess=None,\n",
    ")\n",
    "\n",
    "# Create dataloaders with RandomSampler for training\n",
    "sampler = torch.utils.data.RandomSampler(\n",
    "    train_dataset,\n",
    "    replacement=True,\n",
    "    num_samples=CFG['train_steps'] * CFG['train_batch_size'],\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CFG['train_batch_size'],\n",
    "    sampler=sampler,\n",
    "    num_workers=0,  # Set to 0 for macOS compatibility\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=100, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=100, num_workers=0)\n",
    "\n",
    "# Initialize models\n",
    "print(\"\\nüèóÔ∏è  Initializing models...\")\n",
    "feature_extractor = MelSpectrogramExtractor().to(DEVICE)\n",
    "model = KeywordSpotter(num_classes=len(CLASSES)).to(DEVICE)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Model parameters: {total_params:,}\")\n",
    "print(f\"Estimated size (float32): {total_params * 4 / 1024:.2f} KB\")\n",
    "print(f\"Estimated size (int8): {total_params / 1024:.2f} KB\")\n",
    "\n",
    "# Loss and optimizer\n",
    "loss_module = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=CFG['learning_rate'])\n",
    "\n",
    "# Scheduler\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer, T_max=CFG['epochs'], eta_min=1e-5\n",
    ")\n",
    "\n",
    "# Validation evaluation function\n",
    "def evaluate(model, feature_extractor, loader, device):\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    total_loss = 0\n",
    "    loss_module = nn.CrossEntropyLoss()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            x = batch['x'].squeeze(1).to(device)\n",
    "            y = batch['y'].to(device)\n",
    "            features = feature_extractor(x)\n",
    "            output = model(features)\n",
    "            predictions = output.argmax(dim=1)\n",
    "            correct += (predictions == y).sum().item()\n",
    "            total += y.size(0)\n",
    "            total_loss += loss_module(output, y).item()\n",
    "    \n",
    "    accuracy = (correct / total) * 100\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    return accuracy, avg_loss\n",
    "\n",
    "# Early stopping setup\n",
    "best_val_acc = 0\n",
    "best_val_loss = float('inf')\n",
    "patience = 10\n",
    "patience_counter = 0\n",
    "best_model_state = None\n",
    "\n",
    "# Training loop\n",
    "print(\"\\nüöÄ Starting training...\")\n",
    "model.train()\n",
    "\n",
    "steps_per_epoch = len(train_loader) // CFG['epochs']\n",
    "current_epoch = 0\n",
    "\n",
    "for step, batch in enumerate(train_loader):\n",
    "    x = batch['x'].squeeze(1).to(DEVICE)  # Remove channel dim from waveform\n",
    "    y = batch['y'].to(DEVICE)\n",
    "    \n",
    "    # Extract features\n",
    "    with torch.no_grad():\n",
    "        features = feature_extractor(x)\n",
    "    \n",
    "    # Forward pass\n",
    "    output = model(features)\n",
    "    loss = loss_module(output, y)\n",
    "    \n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if ((step + 1) % 100) == 0 or step == 0:\n",
    "        print(f'Step={step}; Training Loss={loss.item():.3f}')\n",
    "    \n",
    "    # Check if epoch ended\n",
    "    if (step + 1) % steps_per_epoch == 0:\n",
    "        current_epoch += 1\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        val_acc, val_loss = evaluate(model, feature_extractor, val_loader, DEVICE)\n",
    "        print(f'\\nüìä Epoch {current_epoch}: Val Acc={val_acc:.2f}%, Val Loss={val_loss:.4f}')\n",
    "        \n",
    "        # Early stopping check\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            patience_counter = 0\n",
    "            print(f'‚úÖ New best model! Val Acc={val_acc:.2f}%')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f'‚ö†Ô∏è  No improvement. Patience: {patience_counter}/{patience}')\n",
    "        \n",
    "        if patience_counter >= patience:\n",
    "            print(f'\\nüõë Early stopping at epoch {current_epoch}')\n",
    "            break\n",
    "        \n",
    "        # Learning rate step\n",
    "        scheduler.step()\n",
    "        model.train()\n",
    "\n",
    "# Load best model\n",
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(f'\\n‚úÖ Loaded best model with Val Acc={best_val_acc:.2f}%')\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\nüìä Evaluating model on test set...\")\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        x = batch['x'].squeeze(1).to(DEVICE)\n",
    "        y = batch['y'].to(DEVICE)\n",
    "        \n",
    "        # Extract features\n",
    "        features = feature_extractor(x)\n",
    "        \n",
    "        output = model(features)\n",
    "        predictions = output.argmax(dim=1)\n",
    "        \n",
    "        correct += (predictions == y).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "test_accuracy = (correct / total) * 100\n",
    "print(f'\\nüéØ Test Accuracy: {test_accuracy:.2f}%')\n",
    "\n",
    "if test_accuracy > 99.4:\n",
    "    print(\"‚úÖ PASSED: Accuracy > 99.4%\")\n",
    "else:\n",
    "    print(\"‚ùå FAILED: Accuracy <= 99.4%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": "99a6df57d92146afae7054ec23e004f7",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SAVING MODEL\n",
      "============================================================\n",
      "Model Timestamp: 1764340364\n",
      "\n",
      "üîÑ Moving models to CPU for ONNX export...\n",
      "\n",
      "üì¶ Exporting Feature Extractor to ONNX...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1128 15:32:44.736000 34793 torch/onnx/_internal/exporter/_registration.py:107] torchvision is not installed. Skipping torchvision::nms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `MelSpectrogramExtractor([...]` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `MelSpectrogramExtractor([...]` with `torch.export.export(..., strict=False)`... ‚úÖ\n",
      "[torch.onnx] Run decomposition...\n",
      "[torch.onnx] Run decomposition... ‚úÖ\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ‚úÖ\n",
      "Applied 4 of general pattern rewrite rules.\n",
      "‚úÖ Feature extractor saved: ./saved_models//1764340364_frontend.onnx\n",
      "\n",
      "üì¶ Exporting Model to ONNX...\n",
      "[torch.onnx] Run decomposition... ‚úÖ\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ‚úÖ\n",
      "Applied 4 of general pattern rewrite rules.\n",
      "‚úÖ Feature extractor saved: ./saved_models//1764340364_frontend.onnx\n",
      "\n",
      "üì¶ Exporting Model to ONNX...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1128 15:32:45.084000 34793 torch/onnx/_internal/exporter/_registration.py:107] torchvision is not installed. Skipping torchvision::nms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `KeywordSpotter([...]` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `KeywordSpotter([...]` with `torch.export.export(..., strict=False)`... ‚úÖ\n",
      "[torch.onnx] Run decomposition...\n",
      "[torch.onnx] Run decomposition... ‚úÖ\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ‚úÖ\n",
      "Applied 8 of general pattern rewrite rules.\n",
      "‚úÖ Model saved: ./saved_models//1764340364_model.onnx\n",
      "\n",
      "============================================================\n",
      "SIZE REPORT (ONNX - Float32)\n",
      "============================================================\n",
      "Feature Extractor: 332.49 KB\n",
      "Model: 1022.68 KB\n",
      "Total: 1355.17 KB\n",
      "‚ö†Ô∏è  WARNING: Size > 300 KB - quantization required!\n",
      "\n",
      "üìù Saving hyperparameters and results...\n",
      "‚úÖ Results saved to ./keyword_spotter_results.csv\n",
      "\n",
      "============================================================\n",
      "TRAINING COMPLETE\n",
      "============================================================\n",
      "[torch.onnx] Run decomposition... ‚úÖ\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ‚úÖ\n",
      "Applied 8 of general pattern rewrite rules.\n",
      "‚úÖ Model saved: ./saved_models//1764340364_model.onnx\n",
      "\n",
      "============================================================\n",
      "SIZE REPORT (ONNX - Float32)\n",
      "============================================================\n",
      "Feature Extractor: 332.49 KB\n",
      "Model: 1022.68 KB\n",
      "Total: 1355.17 KB\n",
      "‚ö†Ô∏è  WARNING: Size > 300 KB - quantization required!\n",
      "\n",
      "üìù Saving hyperparameters and results...\n",
      "‚úÖ Results saved to ./keyword_spotter_results.csv\n",
      "\n",
      "============================================================\n",
      "TRAINING COMPLETE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================== SAVE MODEL ====================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SAVING MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "timestamp = int(time())\n",
    "saved_model_dir = './saved_models/'\n",
    "if not os.path.exists(saved_model_dir):\n",
    "    os.makedirs(saved_model_dir)\n",
    "\n",
    "print(f'Model Timestamp: {timestamp}')\n",
    "\n",
    "model.eval()\n",
    "feature_extractor.eval()\n",
    "\n",
    "# Move models to CPU for ONNX export (MPS not supported for export)\n",
    "print(\"\\nüîÑ Moving models to CPU for ONNX export...\")\n",
    "model_cpu = model.cpu()\n",
    "feature_extractor_cpu = feature_extractor.cpu()\n",
    "\n",
    "# Export Feature Extractor to ONNX\n",
    "print(\"\\nüì¶ Exporting Feature Extractor to ONNX...\")\n",
    "torch.onnx.export(\n",
    "    feature_extractor_cpu,  # model to export\n",
    "    torch.randn(1, 16000),  # inputs of the model (waveform)\n",
    "    f'{saved_model_dir}/{timestamp}_frontend.onnx',  # filename of the ONNX model\n",
    "    input_names=['input'],  # input name in the ONNX model\n",
    "    dynamo=True,\n",
    "    optimize=True,\n",
    "    report=False,\n",
    "    external_data=False,\n",
    ")\n",
    "print(f\"‚úÖ Feature extractor saved: {saved_model_dir}/{timestamp}_frontend.onnx\")\n",
    "\n",
    "# Export Model to ONNX\n",
    "print(\"\\nüì¶ Exporting Model to ONNX...\")\n",
    "# Get a sample waveform from training dataset and extract features\n",
    "sample_waveform = train_dataset[0]['x'].squeeze(0).unsqueeze(0).cpu()  # (1, 16000)\n",
    "sample_features = feature_extractor_cpu(sample_waveform)  # (1, 1, n_mels, time)\n",
    "torch.onnx.export(\n",
    "    model_cpu,  # model to export\n",
    "    sample_features,  # inputs of the model (mel-spectrogram features)\n",
    "    f'{saved_model_dir}/{timestamp}_model.onnx',  # filename of the ONNX model\n",
    "    input_names=['input'],  # input name in the ONNX model\n",
    "    dynamo=True,\n",
    "    optimize=True,\n",
    "    report=False,\n",
    "    external_data=False,\n",
    ")\n",
    "print(f\"‚úÖ Model saved: {saved_model_dir}/{timestamp}_model.onnx\")\n",
    "\n",
    "# Check sizes\n",
    "fe_size = os.path.getsize(f'{saved_model_dir}/{timestamp}_frontend.onnx') / 1024\n",
    "model_size = os.path.getsize(f'{saved_model_dir}/{timestamp}_model.onnx') / 1024\n",
    "total_size = fe_size + model_size\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SIZE REPORT (ONNX - Float32)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Feature Extractor: {fe_size:.2f} KB\")\n",
    "print(f\"Model: {model_size:.2f} KB\")\n",
    "print(f\"Total: {total_size:.2f} KB\")\n",
    "\n",
    "if total_size < 300:\n",
    "    print(\"‚úÖ PASSED: Total size < 300 KB (before quantization)\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  WARNING: Size > 300 KB - quantization required!\")\n",
    "\n",
    "# Save Hyperparameters & Results\n",
    "print(\"\\nüìù Saving hyperparameters and results...\")\n",
    "output_dict = {\n",
    "    'timestamp': timestamp,\n",
    "    **CFG,\n",
    "    'test_accuracy': test_accuracy\n",
    "}\n",
    "\n",
    "df = pd.DataFrame([output_dict])\n",
    "output_path = './keyword_spotter_results.csv'\n",
    "df.to_csv(output_path, mode='a', header=not os.path.exists(output_path), index=False)\n",
    "print(f\"‚úÖ Results saved to {output_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(\"=\"*60)\n"
   ]
  }
 ],
 "metadata": {
  "deepnote_notebook_id": "c0fbadf4c9c044908423f738834a5ee0",
  "kernelspec": {
   "display_name": "hw2-Xe6H3gEB-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
