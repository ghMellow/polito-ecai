{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "6791d003220b4b65956097c8a4c6f9ae",
    "deepnote_cell_type": "code",
    "execution_context_id": "f5831625-1df5-4e2f-8f38-79330cac3e8c",
    "execution_millis": 9964,
    "execution_start": 1764324392899,
    "source_hash": "6a74492e"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "from time import time\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from msc_dataset import MSCDataset\n",
    "\n",
    "# For data augmentation\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Device setup for Mac M4 Pro (MPS), CUDA (NVIDIA), or CPU fallback\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device('mps')\n",
    "elif torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "2bf1095ce3714193a5704972d8eabc47",
    "deepnote_cell_type": "code",
    "execution_context_id": "f5831625-1df5-4e2f-8f38-79330cac3e8c",
    "execution_millis": 0,
    "execution_start": 1764324402909,
    "source_hash": "2bb072ee"
   },
   "outputs": [],
   "source": [
    "# ==================== CONFIGURATION ====================\n",
    "CFG = {\n",
    "    'sampling_rate': 16000,\n",
    "    'frame_length_in_s': 0.04,\n",
    "    'frame_step_in_s': 0.02,\n",
    "    'n_mels': 40,\n",
    "    'f_min': 20,\n",
    "    'f_max': 4000,\n",
    "    'seed': 42,\n",
    "    \n",
    "    # Training Parameters\n",
    "    'train_steps': 6000,\n",
    "    'train_batch_size': 32,\n",
    "    'learning_rate': 0.0005,\n",
    "    'epochs': 60,\n",
    "    \n",
    "    # Data Augmentation\n",
    "    'time_shift_ms': 80,\n",
    "    'noise_level': 0.002,\n",
    "    'time_stretch_factor': 0.06,\n",
    "    \n",
    "    # Label Smoothing\n",
    "    'label_smoothing': 0.1,\n",
    "}\n",
    "\n",
    "CLASSES = ['stop', 'up']\n",
    "\n",
    "# Set Deterministic Behaviour\n",
    "torch.manual_seed(CFG['seed'])\n",
    "np.random.seed(CFG['seed'])\n",
    "random.seed(CFG['seed'])\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "ecbf3afbfac942669a020b568e53f6e7",
    "deepnote_cell_type": "code",
    "execution_context_id": "f5831625-1df5-4e2f-8f38-79330cac3e8c",
    "execution_millis": 0,
    "execution_start": 1764324402959,
    "source_hash": "ec07639e"
   },
   "outputs": [],
   "source": [
    "# ==================== MEL-SPECTROGRAM FEATURE EXTRACTOR ====================\n",
    "class MelSpectrogramExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mel_transform = torchaudio.transforms.MelSpectrogram(\n",
    "            sample_rate=CFG['sampling_rate'],\n",
    "            n_fft=int(CFG['frame_length_in_s'] * CFG['sampling_rate']),\n",
    "            hop_length=int(CFG['frame_step_in_s'] * CFG['sampling_rate']),\n",
    "            n_mels=CFG['n_mels'],\n",
    "            f_min=CFG['f_min'],\n",
    "            f_max=CFG['f_max'],\n",
    "            window_fn=torch.hann_window,\n",
    "            power=2.0,\n",
    "            normalized=False,\n",
    "            center=True,\n",
    "            pad_mode=\"reflect\"\n",
    "        )\n",
    "        \n",
    "    def forward(self, waveform):\n",
    "        mel_spec = self.mel_transform(waveform)\n",
    "        log_mel = torch.log(mel_spec + 1e-9)\n",
    "        log_mel = (log_mel - log_mel.mean(dim=[1, 2], keepdim=True)) / (log_mel.std(dim=[1, 2], keepdim=True) + 1e-9)\n",
    "        return log_mel.unsqueeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== DATA AUGMENTATION ====================\n",
    "class AudioAugmentation:\n",
    "    def __init__(self, config, training=True):\n",
    "        self.config = config\n",
    "        self.training = training\n",
    "        \n",
    "    def time_shift(self, waveform):\n",
    "        if not self.training or random.random() > 0.5:\n",
    "            return waveform\n",
    "            \n",
    "        shift_samples = int(random.uniform(-self.config['time_shift_ms'], \n",
    "                                          self.config['time_shift_ms']) \n",
    "                          * self.config['sampling_rate'] / 1000)\n",
    "        return torch.roll(waveform, shifts=shift_samples, dims=-1)\n",
    "    \n",
    "    def add_noise(self, waveform):\n",
    "        if not self.training or random.random() > 0.5:\n",
    "            return waveform\n",
    "            \n",
    "        noise = torch.randn_like(waveform) * self.config['noise_level']\n",
    "        return waveform + noise\n",
    "    \n",
    "    def time_stretch(self, waveform):\n",
    "        if not self.training or random.random() > 0.5:\n",
    "            return waveform\n",
    "            \n",
    "        rate = 1.0 + random.uniform(-self.config['time_stretch_factor'], \n",
    "                                    self.config['time_stretch_factor'])\n",
    "        \n",
    "        stretched = F.interpolate(\n",
    "            waveform.unsqueeze(0), \n",
    "            size=int(waveform.shape[-1] * rate),\n",
    "            mode='linear',\n",
    "            align_corners=False\n",
    "        ).squeeze(0)\n",
    "        \n",
    "        target_len = waveform.shape[-1]\n",
    "        if stretched.shape[-1] < target_len:\n",
    "            stretched = F.pad(stretched, (0, target_len - stretched.shape[-1]))\n",
    "        else:\n",
    "            stretched = stretched[..., :target_len]\n",
    "            \n",
    "        return stretched\n",
    "    \n",
    "    def __call__(self, waveform):\n",
    "        waveform = self.time_shift(waveform)\n",
    "        waveform = self.add_noise(waveform)\n",
    "        waveform = self.time_stretch(waveform)\n",
    "        return waveform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "69e8d27312ad462980b748e61e3b30c5",
    "deepnote_cell_type": "code",
    "execution_context_id": "f5831625-1df5-4e2f-8f38-79330cac3e8c",
    "execution_millis": 1,
    "execution_start": 1764324403019,
    "source_hash": "688087c5"
   },
   "outputs": [],
   "source": [
    "# ==================== CNN MODEL ====================\n",
    "class KeywordSpotterV2(nn.Module):\n",
    "    def __init__(self, num_classes=2, dropout=0.35):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.dropout1 = nn.Dropout2d(dropout * 0.3)\n",
    "        \n",
    "        self.conv2a = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2a = nn.BatchNorm2d(64)\n",
    "        self.relu2a = nn.ReLU(inplace=True)\n",
    "        self.conv2b = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.bn2b = nn.BatchNorm2d(64)\n",
    "        self.relu2b = nn.ReLU(inplace=True)\n",
    "        self.dropout2 = nn.Dropout2d(dropout * 0.3)\n",
    "        \n",
    "        self.downsample1 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=1, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(64)\n",
    "        )\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "        self.dropout3 = nn.Dropout2d(dropout * 0.5)\n",
    "        \n",
    "        self.conv4a = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn4a = nn.BatchNorm2d(128)\n",
    "        self.relu4a = nn.ReLU(inplace=True)\n",
    "        self.conv4b = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn4b = nn.BatchNorm2d(128)\n",
    "        self.relu4b = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn5 = nn.BatchNorm2d(256)\n",
    "        self.relu5 = nn.ReLU(inplace=True)\n",
    "        self.dropout5 = nn.Dropout2d(dropout)\n",
    "        \n",
    "        self.attention = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(256, 64, kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 256, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        self.dropout_fc = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(256, num_classes, bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.dropout1(self.relu1(self.bn1(self.conv1(x))))\n",
    "        \n",
    "        identity = self.downsample1(x)\n",
    "        x = self.relu2a(self.bn2a(self.conv2a(x)))\n",
    "        x = self.bn2b(self.conv2b(x))\n",
    "        x = self.relu2b(x + identity)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = self.dropout3(self.relu3(self.bn3(self.conv3(x))))\n",
    "        \n",
    "        identity = x\n",
    "        x = self.relu4a(self.bn4a(self.conv4a(x)))\n",
    "        x = self.bn4b(self.conv4b(x))\n",
    "        x = self.relu4b(x + identity)\n",
    "        \n",
    "        x = self.dropout5(self.relu5(self.bn5(self.conv5(x))))\n",
    "        \n",
    "        att = self.attention(x)\n",
    "        x = x * att\n",
    "        \n",
    "        x = self.gap(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout_fc(x)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "921d386640ed4102b50d9506b5682916",
    "deepnote_cell_type": "code",
    "execution_context_id": "f5831625-1df5-4e2f-8f38-79330cac3e8c",
    "execution_millis": 41,
    "execution_start": 1764324403069,
    "source_hash": "5b3f3265"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "UP/STOP KEYWORD SPOTTER\n",
      "============================================================\n",
      "Device: mps\n",
      "Training: epochs=60, batch_size=32, lr=0.0005\n",
      "Augmentation: time_shift=¬±80ms, noise=0.002, stretch=¬±6.0%\n",
      "============================================================\n",
      "\n",
      "üìÅ Loading datasets...\n",
      "Using data folder: ./msc-training\n",
      "Loaded 1600 samples from ./msc-training for classes ['stop', 'up']\n",
      "Using data folder: ./msc-validation\n",
      "Loaded 200 samples from ./msc-validation for classes ['stop', 'up']\n",
      "Using data folder: ./msc-testing\n",
      "Loaded 200 samples from ./msc-testing for classes ['stop', 'up']\n",
      "\n",
      "üèóÔ∏è  Initializing models...\n",
      "Model parameters: 777,346\n",
      "Estimated size (float32): 3036.51 KB\n"
     ]
    }
   ],
   "source": [
    "# ==================== TRAINING SETUP ====================\n",
    "print(\"=\" * 60)\n",
    "print(\"UP/STOP KEYWORD SPOTTER\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Training: epochs={CFG['epochs']}, batch_size={CFG['train_batch_size']}, lr={CFG['learning_rate']}\")\n",
    "print(f\"Augmentation: time_shift=¬±{CFG['time_shift_ms']}ms, noise={CFG['noise_level']}, stretch=¬±{CFG['time_stretch_factor']*100}%\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "transform = MelSpectrogramExtractor()\n",
    "train_augmentation = AudioAugmentation(CFG, training=True)\n",
    "val_augmentation = AudioAugmentation(CFG, training=False)\n",
    "\n",
    "print(\"\\nüìÅ Loading datasets...\")\n",
    "train_dataset = MSCDataset(\n",
    "    root='.',\n",
    "    classes=CLASSES,\n",
    "    split='training',\n",
    "    preprocess=None,\n",
    ")\n",
    "\n",
    "val_dataset = MSCDataset(\n",
    "    root='.',\n",
    "    classes=CLASSES,\n",
    "    split='validation',\n",
    "    preprocess=None,\n",
    ")\n",
    "\n",
    "test_dataset = MSCDataset(\n",
    "    root='.',\n",
    "    classes=CLASSES,\n",
    "    split='testing',\n",
    "    preprocess=None,\n",
    ")\n",
    "\n",
    "sampler = torch.utils.data.RandomSampler(\n",
    "    train_dataset,\n",
    "    replacement=True,\n",
    "    num_samples=CFG['train_steps'] * CFG['train_batch_size'],\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CFG['train_batch_size'],\n",
    "    sampler=sampler,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=100, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=100, num_workers=0)\n",
    "\n",
    "print(\"\\nüèóÔ∏è  Initializing models...\")\n",
    "feature_extractor = MelSpectrogramExtractor().to(DEVICE)\n",
    "model = KeywordSpotterV2(num_classes=len(CLASSES), dropout=0.3).to(DEVICE)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Model parameters: {total_params:,}\")\n",
    "print(f\"Estimated size (float32): {total_params * 4 / 1024:.2f} KB\")\n",
    "\n",
    "loss_module = nn.CrossEntropyLoss(label_smoothing=CFG['label_smoothing'])\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), \n",
    "    lr=CFG['learning_rate'], \n",
    "    weight_decay=2e-4,\n",
    "    betas=(0.9, 0.999)\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optimizer, \n",
    "    T_0=10,\n",
    "    T_mult=2,\n",
    "    eta_min=1e-7\n",
    ")\n",
    "\n",
    "best_val_acc = 0\n",
    "best_val_loss = float('inf')\n",
    "patience = 20\n",
    "patience_counter = 0\n",
    "best_model_state = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== TRAINING & EVALUATION FUNCTIONS ====================\n",
    "def evaluate(model, feature_extractor, loader, device):\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    total_loss = 0\n",
    "    loss_module = nn.CrossEntropyLoss()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            x = batch['x'].squeeze(1).to(device)\n",
    "            y = batch['y'].to(device)\n",
    "            features = feature_extractor(x)\n",
    "            output = model(features)\n",
    "            predictions = output.argmax(dim=1)\n",
    "            correct += (predictions == y).sum().item()\n",
    "            total += y.size(0)\n",
    "            total_loss += loss_module(output, y).item()\n",
    "    \n",
    "    accuracy = (correct / total) * 100\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    return accuracy, avg_loss\n",
    "\n",
    "\n",
    "def train_epoch(model, feature_extractor, train_loader, optimizer, loss_module, device, \n",
    "                steps_per_epoch, current_epoch, augmentation):\n",
    "    model.train()\n",
    "    \n",
    "    start_step = current_epoch * steps_per_epoch\n",
    "    end_step = start_step + steps_per_epoch\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    step_count = 0\n",
    "    \n",
    "    for step, batch in enumerate(train_loader):\n",
    "        if step < start_step:\n",
    "            continue\n",
    "        if step >= end_step:\n",
    "            break\n",
    "            \n",
    "        x = batch['x'].squeeze(1)\n",
    "        y = batch['y'].to(device)\n",
    "        \n",
    "        x_augmented = []\n",
    "        for i in range(x.shape[0]):\n",
    "            aug_sample = augmentation(x[i:i+1])\n",
    "            x_augmented.append(aug_sample)\n",
    "        x = torch.cat(x_augmented, dim=0).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            features = feature_extractor(x)\n",
    "        \n",
    "        output = model(features)\n",
    "        loss = loss_module(output, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        step_count += 1\n",
    "        \n",
    "        if ((step + 1) % 100) == 0 or step == 0:\n",
    "            print(f'Step={step}; Training Loss={loss.item():.4f}')\n",
    "    \n",
    "    avg_epoch_loss = epoch_loss / step_count if step_count > 0 else 0\n",
    "    return avg_epoch_loss\n",
    "\n",
    "\n",
    "def test_model(model, feature_extractor, test_loader, device):\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            x = batch['x'].squeeze(1).to(device)\n",
    "            y = batch['y'].to(device)\n",
    "            features = feature_extractor(x)\n",
    "            output = model(features)\n",
    "            predictions = output.argmax(dim=1)\n",
    "            correct += (predictions == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    \n",
    "    accuracy = (correct / total) * 100\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Starting training...\n",
      "\n",
      "============================================================\n",
      "EPOCH 1/60\n",
      "============================================================\n",
      "Step=0; Training Loss=0.6940\n",
      "Step=0; Training Loss=0.6940\n",
      "Step=99; Training Loss=0.4114\n",
      "\n",
      "üìä Epoch 1 Summary:\n",
      "   Train Loss: 0.5773\n",
      "   Val Acc: 87.50%\n",
      "   Val Loss: 0.3306\n",
      "   Learning Rate: 0.000500\n",
      "‚úÖ New best model! Val Acc=87.50%\n",
      "\n",
      "============================================================\n",
      "EPOCH 2/60\n",
      "============================================================\n",
      "Step=99; Training Loss=0.4114\n",
      "\n",
      "üìä Epoch 1 Summary:\n",
      "   Train Loss: 0.5773\n",
      "   Val Acc: 87.50%\n",
      "   Val Loss: 0.3306\n",
      "   Learning Rate: 0.000500\n",
      "‚úÖ New best model! Val Acc=87.50%\n",
      "\n",
      "============================================================\n",
      "EPOCH 2/60\n",
      "============================================================\n",
      "Step=199; Training Loss=0.4022\n",
      "\n",
      "üìä Epoch 2 Summary:\n",
      "   Train Loss: 0.4307\n",
      "   Val Acc: 79.00%\n",
      "   Val Loss: 0.4314\n",
      "   Learning Rate: 0.000488\n",
      "‚è≥ No improvement. Patience: 1/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 3/60\n",
      "============================================================\n",
      "Step=199; Training Loss=0.4022\n",
      "\n",
      "üìä Epoch 2 Summary:\n",
      "   Train Loss: 0.4307\n",
      "   Val Acc: 79.00%\n",
      "   Val Loss: 0.4314\n",
      "   Learning Rate: 0.000488\n",
      "‚è≥ No improvement. Patience: 1/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 3/60\n",
      "============================================================\n",
      "Step=299; Training Loss=0.3899\n",
      "\n",
      "üìä Epoch 3 Summary:\n",
      "   Train Loss: 0.3917\n",
      "   Val Acc: 91.50%\n",
      "   Val Loss: 0.2261\n",
      "   Learning Rate: 0.000452\n",
      "‚úÖ New best model! Val Acc=91.50%\n",
      "\n",
      "============================================================\n",
      "EPOCH 4/60\n",
      "============================================================\n",
      "Step=299; Training Loss=0.3899\n",
      "\n",
      "üìä Epoch 3 Summary:\n",
      "   Train Loss: 0.3917\n",
      "   Val Acc: 91.50%\n",
      "   Val Loss: 0.2261\n",
      "   Learning Rate: 0.000452\n",
      "‚úÖ New best model! Val Acc=91.50%\n",
      "\n",
      "============================================================\n",
      "EPOCH 4/60\n",
      "============================================================\n",
      "Step=399; Training Loss=0.3517\n",
      "\n",
      "üìä Epoch 4 Summary:\n",
      "   Train Loss: 0.3428\n",
      "   Val Acc: 80.50%\n",
      "   Val Loss: 0.4219\n",
      "   Learning Rate: 0.000397\n",
      "‚è≥ No improvement. Patience: 1/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 5/60\n",
      "============================================================\n",
      "Step=399; Training Loss=0.3517\n",
      "\n",
      "üìä Epoch 4 Summary:\n",
      "   Train Loss: 0.3428\n",
      "   Val Acc: 80.50%\n",
      "   Val Loss: 0.4219\n",
      "   Learning Rate: 0.000397\n",
      "‚è≥ No improvement. Patience: 1/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 5/60\n",
      "============================================================\n",
      "Step=499; Training Loss=0.2680\n",
      "\n",
      "üìä Epoch 5 Summary:\n",
      "   Train Loss: 0.3155\n",
      "   Val Acc: 95.50%\n",
      "   Val Loss: 0.1595\n",
      "   Learning Rate: 0.000327\n",
      "‚úÖ New best model! Val Acc=95.50%\n",
      "\n",
      "============================================================\n",
      "EPOCH 6/60\n",
      "============================================================\n",
      "Step=499; Training Loss=0.2680\n",
      "\n",
      "üìä Epoch 5 Summary:\n",
      "   Train Loss: 0.3155\n",
      "   Val Acc: 95.50%\n",
      "   Val Loss: 0.1595\n",
      "   Learning Rate: 0.000327\n",
      "‚úÖ New best model! Val Acc=95.50%\n",
      "\n",
      "============================================================\n",
      "EPOCH 6/60\n",
      "============================================================\n",
      "Step=599; Training Loss=0.3741\n",
      "\n",
      "üìä Epoch 6 Summary:\n",
      "   Train Loss: 0.2761\n",
      "   Val Acc: 95.50%\n",
      "   Val Loss: 0.1465\n",
      "   Learning Rate: 0.000250\n",
      "‚è≥ No improvement. Patience: 1/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 7/60\n",
      "============================================================\n",
      "Step=599; Training Loss=0.3741\n",
      "\n",
      "üìä Epoch 6 Summary:\n",
      "   Train Loss: 0.2761\n",
      "   Val Acc: 95.50%\n",
      "   Val Loss: 0.1465\n",
      "   Learning Rate: 0.000250\n",
      "‚è≥ No improvement. Patience: 1/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 7/60\n",
      "============================================================\n",
      "Step=699; Training Loss=0.3001\n",
      "\n",
      "üìä Epoch 7 Summary:\n",
      "   Train Loss: 0.2683\n",
      "   Val Acc: 96.50%\n",
      "   Val Loss: 0.1384\n",
      "   Learning Rate: 0.000173\n",
      "‚úÖ New best model! Val Acc=96.50%\n",
      "\n",
      "============================================================\n",
      "EPOCH 8/60\n",
      "============================================================\n",
      "Step=699; Training Loss=0.3001\n",
      "\n",
      "üìä Epoch 7 Summary:\n",
      "   Train Loss: 0.2683\n",
      "   Val Acc: 96.50%\n",
      "   Val Loss: 0.1384\n",
      "   Learning Rate: 0.000173\n",
      "‚úÖ New best model! Val Acc=96.50%\n",
      "\n",
      "============================================================\n",
      "EPOCH 8/60\n",
      "============================================================\n",
      "Step=799; Training Loss=0.3187\n",
      "\n",
      "üìä Epoch 8 Summary:\n",
      "   Train Loss: 0.2539\n",
      "   Val Acc: 96.00%\n",
      "   Val Loss: 0.1417\n",
      "   Learning Rate: 0.000103\n",
      "‚è≥ No improvement. Patience: 1/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 9/60\n",
      "============================================================\n",
      "Step=799; Training Loss=0.3187\n",
      "\n",
      "üìä Epoch 8 Summary:\n",
      "   Train Loss: 0.2539\n",
      "   Val Acc: 96.00%\n",
      "   Val Loss: 0.1417\n",
      "   Learning Rate: 0.000103\n",
      "‚è≥ No improvement. Patience: 1/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 9/60\n",
      "============================================================\n",
      "Step=899; Training Loss=0.2338\n",
      "\n",
      "üìä Epoch 9 Summary:\n",
      "   Train Loss: 0.2511\n",
      "   Val Acc: 96.50%\n",
      "   Val Loss: 0.1208\n",
      "   Learning Rate: 0.000048\n",
      "‚è≥ No improvement. Patience: 2/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 10/60\n",
      "============================================================\n",
      "Step=899; Training Loss=0.2338\n",
      "\n",
      "üìä Epoch 9 Summary:\n",
      "   Train Loss: 0.2511\n",
      "   Val Acc: 96.50%\n",
      "   Val Loss: 0.1208\n",
      "   Learning Rate: 0.000048\n",
      "‚è≥ No improvement. Patience: 2/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 10/60\n",
      "============================================================\n",
      "Step=999; Training Loss=0.2350\n",
      "\n",
      "üìä Epoch 10 Summary:\n",
      "   Train Loss: 0.2490\n",
      "   Val Acc: 96.50%\n",
      "   Val Loss: 0.1209\n",
      "   Learning Rate: 0.000012\n",
      "‚è≥ No improvement. Patience: 3/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 11/60\n",
      "============================================================\n",
      "Step=999; Training Loss=0.2350\n",
      "\n",
      "üìä Epoch 10 Summary:\n",
      "   Train Loss: 0.2490\n",
      "   Val Acc: 96.50%\n",
      "   Val Loss: 0.1209\n",
      "   Learning Rate: 0.000012\n",
      "‚è≥ No improvement. Patience: 3/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 11/60\n",
      "============================================================\n",
      "Step=1099; Training Loss=0.3954\n",
      "\n",
      "üìä Epoch 11 Summary:\n",
      "   Train Loss: 0.2736\n",
      "   Val Acc: 93.50%\n",
      "   Val Loss: 0.1564\n",
      "   Learning Rate: 0.000500\n",
      "‚è≥ No improvement. Patience: 4/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 12/60\n",
      "============================================================\n",
      "Step=1099; Training Loss=0.3954\n",
      "\n",
      "üìä Epoch 11 Summary:\n",
      "   Train Loss: 0.2736\n",
      "   Val Acc: 93.50%\n",
      "   Val Loss: 0.1564\n",
      "   Learning Rate: 0.000500\n",
      "‚è≥ No improvement. Patience: 4/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 12/60\n",
      "============================================================\n",
      "Step=1199; Training Loss=0.2535\n",
      "\n",
      "üìä Epoch 12 Summary:\n",
      "   Train Loss: 0.2726\n",
      "   Val Acc: 96.00%\n",
      "   Val Loss: 0.1485\n",
      "   Learning Rate: 0.000497\n",
      "‚è≥ No improvement. Patience: 5/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 13/60\n",
      "============================================================\n",
      "Step=1199; Training Loss=0.2535\n",
      "\n",
      "üìä Epoch 12 Summary:\n",
      "   Train Loss: 0.2726\n",
      "   Val Acc: 96.00%\n",
      "   Val Loss: 0.1485\n",
      "   Learning Rate: 0.000497\n",
      "‚è≥ No improvement. Patience: 5/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 13/60\n",
      "============================================================\n",
      "Step=1299; Training Loss=0.2298\n",
      "\n",
      "üìä Epoch 13 Summary:\n",
      "   Train Loss: 0.2455\n",
      "   Val Acc: 96.50%\n",
      "   Val Loss: 0.1316\n",
      "   Learning Rate: 0.000488\n",
      "‚è≥ No improvement. Patience: 6/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 14/60\n",
      "============================================================\n",
      "Step=1299; Training Loss=0.2298\n",
      "\n",
      "üìä Epoch 13 Summary:\n",
      "   Train Loss: 0.2455\n",
      "   Val Acc: 96.50%\n",
      "   Val Loss: 0.1316\n",
      "   Learning Rate: 0.000488\n",
      "‚è≥ No improvement. Patience: 6/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 14/60\n",
      "============================================================\n",
      "Step=1399; Training Loss=0.2578\n",
      "\n",
      "üìä Epoch 14 Summary:\n",
      "   Train Loss: 0.2552\n",
      "   Val Acc: 97.50%\n",
      "   Val Loss: 0.1262\n",
      "   Learning Rate: 0.000473\n",
      "‚úÖ New best model! Val Acc=97.50%\n",
      "\n",
      "============================================================\n",
      "EPOCH 15/60\n",
      "============================================================\n",
      "Step=1399; Training Loss=0.2578\n",
      "\n",
      "üìä Epoch 14 Summary:\n",
      "   Train Loss: 0.2552\n",
      "   Val Acc: 97.50%\n",
      "   Val Loss: 0.1262\n",
      "   Learning Rate: 0.000473\n",
      "‚úÖ New best model! Val Acc=97.50%\n",
      "\n",
      "============================================================\n",
      "EPOCH 15/60\n",
      "============================================================\n",
      "Step=1499; Training Loss=0.2129\n",
      "\n",
      "üìä Epoch 15 Summary:\n",
      "   Train Loss: 0.2388\n",
      "   Val Acc: 87.50%\n",
      "   Val Loss: 0.2684\n",
      "   Learning Rate: 0.000452\n",
      "‚è≥ No improvement. Patience: 1/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 16/60\n",
      "============================================================\n",
      "Step=1499; Training Loss=0.2129\n",
      "\n",
      "üìä Epoch 15 Summary:\n",
      "   Train Loss: 0.2388\n",
      "   Val Acc: 87.50%\n",
      "   Val Loss: 0.2684\n",
      "   Learning Rate: 0.000452\n",
      "‚è≥ No improvement. Patience: 1/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 16/60\n",
      "============================================================\n",
      "Step=1599; Training Loss=0.2032\n",
      "\n",
      "üìä Epoch 16 Summary:\n",
      "   Train Loss: 0.2396\n",
      "   Val Acc: 97.00%\n",
      "   Val Loss: 0.1317\n",
      "   Learning Rate: 0.000427\n",
      "‚è≥ No improvement. Patience: 2/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 17/60\n",
      "============================================================\n",
      "Step=1599; Training Loss=0.2032\n",
      "\n",
      "üìä Epoch 16 Summary:\n",
      "   Train Loss: 0.2396\n",
      "   Val Acc: 97.00%\n",
      "   Val Loss: 0.1317\n",
      "   Learning Rate: 0.000427\n",
      "‚è≥ No improvement. Patience: 2/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 17/60\n",
      "============================================================\n",
      "Step=1699; Training Loss=0.2212\n",
      "\n",
      "üìä Epoch 17 Summary:\n",
      "   Train Loss: 0.2384\n",
      "   Val Acc: 97.00%\n",
      "   Val Loss: 0.1133\n",
      "   Learning Rate: 0.000397\n",
      "‚è≥ No improvement. Patience: 3/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 18/60\n",
      "============================================================\n",
      "Step=1699; Training Loss=0.2212\n",
      "\n",
      "üìä Epoch 17 Summary:\n",
      "   Train Loss: 0.2384\n",
      "   Val Acc: 97.00%\n",
      "   Val Loss: 0.1133\n",
      "   Learning Rate: 0.000397\n",
      "‚è≥ No improvement. Patience: 3/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 18/60\n",
      "============================================================\n",
      "Step=1799; Training Loss=0.2326\n",
      "\n",
      "üìä Epoch 18 Summary:\n",
      "   Train Loss: 0.2314\n",
      "   Val Acc: 96.50%\n",
      "   Val Loss: 0.1221\n",
      "   Learning Rate: 0.000364\n",
      "‚è≥ No improvement. Patience: 4/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 19/60\n",
      "============================================================\n",
      "Step=1799; Training Loss=0.2326\n",
      "\n",
      "üìä Epoch 18 Summary:\n",
      "   Train Loss: 0.2314\n",
      "   Val Acc: 96.50%\n",
      "   Val Loss: 0.1221\n",
      "   Learning Rate: 0.000364\n",
      "‚è≥ No improvement. Patience: 4/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 19/60\n",
      "============================================================\n",
      "Step=1899; Training Loss=0.2062\n",
      "\n",
      "üìä Epoch 19 Summary:\n",
      "   Train Loss: 0.2344\n",
      "   Val Acc: 93.50%\n",
      "   Val Loss: 0.1596\n",
      "   Learning Rate: 0.000327\n",
      "‚è≥ No improvement. Patience: 5/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 20/60\n",
      "============================================================\n",
      "Step=1899; Training Loss=0.2062\n",
      "\n",
      "üìä Epoch 19 Summary:\n",
      "   Train Loss: 0.2344\n",
      "   Val Acc: 93.50%\n",
      "   Val Loss: 0.1596\n",
      "   Learning Rate: 0.000327\n",
      "‚è≥ No improvement. Patience: 5/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 20/60\n",
      "============================================================\n",
      "Step=1999; Training Loss=0.2078\n",
      "\n",
      "üìä Epoch 20 Summary:\n",
      "   Train Loss: 0.2260\n",
      "   Val Acc: 97.50%\n",
      "   Val Loss: 0.1103\n",
      "   Learning Rate: 0.000289\n",
      "‚è≥ No improvement. Patience: 6/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 21/60\n",
      "============================================================\n",
      "Step=1999; Training Loss=0.2078\n",
      "\n",
      "üìä Epoch 20 Summary:\n",
      "   Train Loss: 0.2260\n",
      "   Val Acc: 97.50%\n",
      "   Val Loss: 0.1103\n",
      "   Learning Rate: 0.000289\n",
      "‚è≥ No improvement. Patience: 6/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 21/60\n",
      "============================================================\n",
      "Step=2099; Training Loss=0.2157\n",
      "\n",
      "üìä Epoch 21 Summary:\n",
      "   Train Loss: 0.2232\n",
      "   Val Acc: 97.50%\n",
      "   Val Loss: 0.1061\n",
      "   Learning Rate: 0.000250\n",
      "‚è≥ No improvement. Patience: 7/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 22/60\n",
      "============================================================\n",
      "Step=2099; Training Loss=0.2157\n",
      "\n",
      "üìä Epoch 21 Summary:\n",
      "   Train Loss: 0.2232\n",
      "   Val Acc: 97.50%\n",
      "   Val Loss: 0.1061\n",
      "   Learning Rate: 0.000250\n",
      "‚è≥ No improvement. Patience: 7/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 22/60\n",
      "============================================================\n",
      "Step=2199; Training Loss=0.2029\n",
      "\n",
      "üìä Epoch 22 Summary:\n",
      "   Train Loss: 0.2209\n",
      "   Val Acc: 97.50%\n",
      "   Val Loss: 0.1068\n",
      "   Learning Rate: 0.000211\n",
      "‚è≥ No improvement. Patience: 8/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 23/60\n",
      "============================================================\n",
      "Step=2199; Training Loss=0.2029\n",
      "\n",
      "üìä Epoch 22 Summary:\n",
      "   Train Loss: 0.2209\n",
      "   Val Acc: 97.50%\n",
      "   Val Loss: 0.1068\n",
      "   Learning Rate: 0.000211\n",
      "‚è≥ No improvement. Patience: 8/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 23/60\n",
      "============================================================\n",
      "Step=2299; Training Loss=0.2007\n",
      "\n",
      "üìä Epoch 23 Summary:\n",
      "   Train Loss: 0.2225\n",
      "   Val Acc: 97.50%\n",
      "   Val Loss: 0.1062\n",
      "   Learning Rate: 0.000173\n",
      "‚è≥ No improvement. Patience: 9/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 24/60\n",
      "============================================================\n",
      "Step=2299; Training Loss=0.2007\n",
      "\n",
      "üìä Epoch 23 Summary:\n",
      "   Train Loss: 0.2225\n",
      "   Val Acc: 97.50%\n",
      "   Val Loss: 0.1062\n",
      "   Learning Rate: 0.000173\n",
      "‚è≥ No improvement. Patience: 9/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 24/60\n",
      "============================================================\n",
      "Step=2399; Training Loss=0.2022\n",
      "\n",
      "üìä Epoch 24 Summary:\n",
      "   Train Loss: 0.2186\n",
      "   Val Acc: 97.50%\n",
      "   Val Loss: 0.1008\n",
      "   Learning Rate: 0.000137\n",
      "‚è≥ No improvement. Patience: 10/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 25/60\n",
      "============================================================\n",
      "Step=2399; Training Loss=0.2022\n",
      "\n",
      "üìä Epoch 24 Summary:\n",
      "   Train Loss: 0.2186\n",
      "   Val Acc: 97.50%\n",
      "   Val Loss: 0.1008\n",
      "   Learning Rate: 0.000137\n",
      "‚è≥ No improvement. Patience: 10/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 25/60\n",
      "============================================================\n",
      "Step=2499; Training Loss=0.2022\n",
      "\n",
      "üìä Epoch 25 Summary:\n",
      "   Train Loss: 0.2155\n",
      "   Val Acc: 97.00%\n",
      "   Val Loss: 0.1084\n",
      "   Learning Rate: 0.000103\n",
      "‚è≥ No improvement. Patience: 11/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 26/60\n",
      "============================================================\n",
      "Step=2499; Training Loss=0.2022\n",
      "\n",
      "üìä Epoch 25 Summary:\n",
      "   Train Loss: 0.2155\n",
      "   Val Acc: 97.00%\n",
      "   Val Loss: 0.1084\n",
      "   Learning Rate: 0.000103\n",
      "‚è≥ No improvement. Patience: 11/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 26/60\n",
      "============================================================\n",
      "Step=2599; Training Loss=0.2014\n",
      "\n",
      "üìä Epoch 26 Summary:\n",
      "   Train Loss: 0.2128\n",
      "   Val Acc: 97.00%\n",
      "   Val Loss: 0.1133\n",
      "   Learning Rate: 0.000073\n",
      "‚è≥ No improvement. Patience: 12/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 27/60\n",
      "============================================================\n",
      "Step=2599; Training Loss=0.2014\n",
      "\n",
      "üìä Epoch 26 Summary:\n",
      "   Train Loss: 0.2128\n",
      "   Val Acc: 97.00%\n",
      "   Val Loss: 0.1133\n",
      "   Learning Rate: 0.000073\n",
      "‚è≥ No improvement. Patience: 12/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 27/60\n",
      "============================================================\n",
      "Step=2699; Training Loss=0.2005\n",
      "\n",
      "üìä Epoch 27 Summary:\n",
      "   Train Loss: 0.2155\n",
      "   Val Acc: 97.00%\n",
      "   Val Loss: 0.1152\n",
      "   Learning Rate: 0.000048\n",
      "‚è≥ No improvement. Patience: 13/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 28/60\n",
      "============================================================\n",
      "Step=2699; Training Loss=0.2005\n",
      "\n",
      "üìä Epoch 27 Summary:\n",
      "   Train Loss: 0.2155\n",
      "   Val Acc: 97.00%\n",
      "   Val Loss: 0.1152\n",
      "   Learning Rate: 0.000048\n",
      "‚è≥ No improvement. Patience: 13/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 28/60\n",
      "============================================================\n",
      "Step=2799; Training Loss=0.2645\n",
      "\n",
      "üìä Epoch 28 Summary:\n",
      "   Train Loss: 0.2155\n",
      "   Val Acc: 97.00%\n",
      "   Val Loss: 0.1108\n",
      "   Learning Rate: 0.000027\n",
      "‚è≥ No improvement. Patience: 14/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 29/60\n",
      "============================================================\n",
      "Step=2799; Training Loss=0.2645\n",
      "\n",
      "üìä Epoch 28 Summary:\n",
      "   Train Loss: 0.2155\n",
      "   Val Acc: 97.00%\n",
      "   Val Loss: 0.1108\n",
      "   Learning Rate: 0.000027\n",
      "‚è≥ No improvement. Patience: 14/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 29/60\n",
      "============================================================\n",
      "Step=2899; Training Loss=0.2379\n",
      "\n",
      "üìä Epoch 29 Summary:\n",
      "   Train Loss: 0.2144\n",
      "   Val Acc: 97.00%\n",
      "   Val Loss: 0.1092\n",
      "   Learning Rate: 0.000012\n",
      "‚è≥ No improvement. Patience: 15/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 30/60\n",
      "============================================================\n",
      "Step=2899; Training Loss=0.2379\n",
      "\n",
      "üìä Epoch 29 Summary:\n",
      "   Train Loss: 0.2144\n",
      "   Val Acc: 97.00%\n",
      "   Val Loss: 0.1092\n",
      "   Learning Rate: 0.000012\n",
      "‚è≥ No improvement. Patience: 15/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 30/60\n",
      "============================================================\n",
      "Step=2999; Training Loss=0.2145\n",
      "\n",
      "üìä Epoch 30 Summary:\n",
      "   Train Loss: 0.2145\n",
      "   Val Acc: 97.00%\n",
      "   Val Loss: 0.1076\n",
      "   Learning Rate: 0.000003\n",
      "‚è≥ No improvement. Patience: 16/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 31/60\n",
      "============================================================\n",
      "Step=2999; Training Loss=0.2145\n",
      "\n",
      "üìä Epoch 30 Summary:\n",
      "   Train Loss: 0.2145\n",
      "   Val Acc: 97.00%\n",
      "   Val Loss: 0.1076\n",
      "   Learning Rate: 0.000003\n",
      "‚è≥ No improvement. Patience: 16/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 31/60\n",
      "============================================================\n",
      "Step=3099; Training Loss=0.2062\n",
      "\n",
      "üìä Epoch 31 Summary:\n",
      "   Train Loss: 0.2277\n",
      "   Val Acc: 95.50%\n",
      "   Val Loss: 0.1455\n",
      "   Learning Rate: 0.000500\n",
      "‚è≥ No improvement. Patience: 17/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 32/60\n",
      "============================================================\n",
      "Step=3099; Training Loss=0.2062\n",
      "\n",
      "üìä Epoch 31 Summary:\n",
      "   Train Loss: 0.2277\n",
      "   Val Acc: 95.50%\n",
      "   Val Loss: 0.1455\n",
      "   Learning Rate: 0.000500\n",
      "‚è≥ No improvement. Patience: 17/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 32/60\n",
      "============================================================\n",
      "Step=3199; Training Loss=0.2416\n",
      "\n",
      "üìä Epoch 32 Summary:\n",
      "   Train Loss: 0.2395\n",
      "   Val Acc: 89.50%\n",
      "   Val Loss: 0.2639\n",
      "   Learning Rate: 0.000499\n",
      "‚è≥ No improvement. Patience: 18/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 33/60\n",
      "============================================================\n",
      "Step=3199; Training Loss=0.2416\n",
      "\n",
      "üìä Epoch 32 Summary:\n",
      "   Train Loss: 0.2395\n",
      "   Val Acc: 89.50%\n",
      "   Val Loss: 0.2639\n",
      "   Learning Rate: 0.000499\n",
      "‚è≥ No improvement. Patience: 18/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 33/60\n",
      "============================================================\n",
      "Step=3299; Training Loss=0.2125\n",
      "\n",
      "üìä Epoch 33 Summary:\n",
      "   Train Loss: 0.2352\n",
      "   Val Acc: 98.00%\n",
      "   Val Loss: 0.0983\n",
      "   Learning Rate: 0.000497\n",
      "‚úÖ New best model! Val Acc=98.00%\n",
      "\n",
      "============================================================\n",
      "EPOCH 34/60\n",
      "============================================================\n",
      "Step=3299; Training Loss=0.2125\n",
      "\n",
      "üìä Epoch 33 Summary:\n",
      "   Train Loss: 0.2352\n",
      "   Val Acc: 98.00%\n",
      "   Val Loss: 0.0983\n",
      "   Learning Rate: 0.000497\n",
      "‚úÖ New best model! Val Acc=98.00%\n",
      "\n",
      "============================================================\n",
      "EPOCH 34/60\n",
      "============================================================\n",
      "Step=3399; Training Loss=0.2089\n",
      "\n",
      "üìä Epoch 34 Summary:\n",
      "   Train Loss: 0.2340\n",
      "   Val Acc: 97.50%\n",
      "   Val Loss: 0.1171\n",
      "   Learning Rate: 0.000493\n",
      "‚è≥ No improvement. Patience: 1/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 35/60\n",
      "============================================================\n",
      "Step=3399; Training Loss=0.2089\n",
      "\n",
      "üìä Epoch 34 Summary:\n",
      "   Train Loss: 0.2340\n",
      "   Val Acc: 97.50%\n",
      "   Val Loss: 0.1171\n",
      "   Learning Rate: 0.000493\n",
      "‚è≥ No improvement. Patience: 1/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 35/60\n",
      "============================================================\n",
      "Step=3499; Training Loss=0.2385\n",
      "\n",
      "üìä Epoch 35 Summary:\n",
      "   Train Loss: 0.2375\n",
      "   Val Acc: 97.00%\n",
      "   Val Loss: 0.1165\n",
      "   Learning Rate: 0.000488\n",
      "‚è≥ No improvement. Patience: 2/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 36/60\n",
      "============================================================\n",
      "Step=3499; Training Loss=0.2385\n",
      "\n",
      "üìä Epoch 35 Summary:\n",
      "   Train Loss: 0.2375\n",
      "   Val Acc: 97.00%\n",
      "   Val Loss: 0.1165\n",
      "   Learning Rate: 0.000488\n",
      "‚è≥ No improvement. Patience: 2/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 36/60\n",
      "============================================================\n",
      "Step=3599; Training Loss=0.2607\n",
      "\n",
      "üìä Epoch 36 Summary:\n",
      "   Train Loss: 0.2267\n",
      "   Val Acc: 94.00%\n",
      "   Val Loss: 0.1856\n",
      "   Learning Rate: 0.000481\n",
      "‚è≥ No improvement. Patience: 3/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 37/60\n",
      "============================================================\n",
      "Step=3599; Training Loss=0.2607\n",
      "\n",
      "üìä Epoch 36 Summary:\n",
      "   Train Loss: 0.2267\n",
      "   Val Acc: 94.00%\n",
      "   Val Loss: 0.1856\n",
      "   Learning Rate: 0.000481\n",
      "‚è≥ No improvement. Patience: 3/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 37/60\n",
      "============================================================\n",
      "Step=3699; Training Loss=0.2333\n",
      "\n",
      "üìä Epoch 37 Summary:\n",
      "   Train Loss: 0.2238\n",
      "   Val Acc: 95.00%\n",
      "   Val Loss: 0.1296\n",
      "   Learning Rate: 0.000473\n",
      "‚è≥ No improvement. Patience: 4/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 38/60\n",
      "============================================================\n",
      "Step=3699; Training Loss=0.2333\n",
      "\n",
      "üìä Epoch 37 Summary:\n",
      "   Train Loss: 0.2238\n",
      "   Val Acc: 95.00%\n",
      "   Val Loss: 0.1296\n",
      "   Learning Rate: 0.000473\n",
      "‚è≥ No improvement. Patience: 4/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 38/60\n",
      "============================================================\n",
      "Step=3799; Training Loss=0.2015\n",
      "\n",
      "üìä Epoch 38 Summary:\n",
      "   Train Loss: 0.2243\n",
      "   Val Acc: 96.50%\n",
      "   Val Loss: 0.1220\n",
      "   Learning Rate: 0.000463\n",
      "‚è≥ No improvement. Patience: 5/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 39/60\n",
      "============================================================\n",
      "Step=3799; Training Loss=0.2015\n",
      "\n",
      "üìä Epoch 38 Summary:\n",
      "   Train Loss: 0.2243\n",
      "   Val Acc: 96.50%\n",
      "   Val Loss: 0.1220\n",
      "   Learning Rate: 0.000463\n",
      "‚è≥ No improvement. Patience: 5/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 39/60\n",
      "============================================================\n",
      "Step=3899; Training Loss=0.2014\n",
      "\n",
      "üìä Epoch 39 Summary:\n",
      "   Train Loss: 0.2238\n",
      "   Val Acc: 98.00%\n",
      "   Val Loss: 0.1122\n",
      "   Learning Rate: 0.000452\n",
      "‚è≥ No improvement. Patience: 6/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 40/60\n",
      "============================================================\n",
      "Step=3899; Training Loss=0.2014\n",
      "\n",
      "üìä Epoch 39 Summary:\n",
      "   Train Loss: 0.2238\n",
      "   Val Acc: 98.00%\n",
      "   Val Loss: 0.1122\n",
      "   Learning Rate: 0.000452\n",
      "‚è≥ No improvement. Patience: 6/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 40/60\n",
      "============================================================\n",
      "Step=3999; Training Loss=0.2344\n",
      "\n",
      "üìä Epoch 40 Summary:\n",
      "   Train Loss: 0.2210\n",
      "   Val Acc: 98.00%\n",
      "   Val Loss: 0.0978\n",
      "   Learning Rate: 0.000440\n",
      "‚è≥ No improvement. Patience: 7/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 41/60\n",
      "============================================================\n",
      "Step=3999; Training Loss=0.2344\n",
      "\n",
      "üìä Epoch 40 Summary:\n",
      "   Train Loss: 0.2210\n",
      "   Val Acc: 98.00%\n",
      "   Val Loss: 0.0978\n",
      "   Learning Rate: 0.000440\n",
      "‚è≥ No improvement. Patience: 7/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 41/60\n",
      "============================================================\n",
      "Step=4099; Training Loss=0.2132\n",
      "\n",
      "üìä Epoch 41 Summary:\n",
      "   Train Loss: 0.2153\n",
      "   Val Acc: 97.00%\n",
      "   Val Loss: 0.1094\n",
      "   Learning Rate: 0.000427\n",
      "‚è≥ No improvement. Patience: 8/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 42/60\n",
      "============================================================\n",
      "Step=4099; Training Loss=0.2132\n",
      "\n",
      "üìä Epoch 41 Summary:\n",
      "   Train Loss: 0.2153\n",
      "   Val Acc: 97.00%\n",
      "   Val Loss: 0.1094\n",
      "   Learning Rate: 0.000427\n",
      "‚è≥ No improvement. Patience: 8/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 42/60\n",
      "============================================================\n",
      "Step=4199; Training Loss=0.2775\n",
      "\n",
      "üìä Epoch 42 Summary:\n",
      "   Train Loss: 0.2168\n",
      "   Val Acc: 97.50%\n",
      "   Val Loss: 0.1182\n",
      "   Learning Rate: 0.000412\n",
      "‚è≥ No improvement. Patience: 9/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 43/60\n",
      "============================================================\n",
      "Step=4199; Training Loss=0.2775\n",
      "\n",
      "üìä Epoch 42 Summary:\n",
      "   Train Loss: 0.2168\n",
      "   Val Acc: 97.50%\n",
      "   Val Loss: 0.1182\n",
      "   Learning Rate: 0.000412\n",
      "‚è≥ No improvement. Patience: 9/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 43/60\n",
      "============================================================\n",
      "Step=4299; Training Loss=0.2190\n",
      "\n",
      "üìä Epoch 43 Summary:\n",
      "   Train Loss: 0.2222\n",
      "   Val Acc: 97.00%\n",
      "   Val Loss: 0.0947\n",
      "   Learning Rate: 0.000397\n",
      "‚è≥ No improvement. Patience: 10/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 44/60\n",
      "============================================================\n",
      "Step=4299; Training Loss=0.2190\n",
      "\n",
      "üìä Epoch 43 Summary:\n",
      "   Train Loss: 0.2222\n",
      "   Val Acc: 97.00%\n",
      "   Val Loss: 0.0947\n",
      "   Learning Rate: 0.000397\n",
      "‚è≥ No improvement. Patience: 10/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 44/60\n",
      "============================================================\n",
      "Step=4399; Training Loss=0.2118\n",
      "\n",
      "üìä Epoch 44 Summary:\n",
      "   Train Loss: 0.2195\n",
      "   Val Acc: 97.00%\n",
      "   Val Loss: 0.1078\n",
      "   Learning Rate: 0.000381\n",
      "‚è≥ No improvement. Patience: 11/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 45/60\n",
      "============================================================\n",
      "Step=4399; Training Loss=0.2118\n",
      "\n",
      "üìä Epoch 44 Summary:\n",
      "   Train Loss: 0.2195\n",
      "   Val Acc: 97.00%\n",
      "   Val Loss: 0.1078\n",
      "   Learning Rate: 0.000381\n",
      "‚è≥ No improvement. Patience: 11/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 45/60\n",
      "============================================================\n",
      "Step=4499; Training Loss=0.2003\n",
      "\n",
      "üìä Epoch 45 Summary:\n",
      "   Train Loss: 0.2197\n",
      "   Val Acc: 98.50%\n",
      "   Val Loss: 0.0924\n",
      "   Learning Rate: 0.000364\n",
      "‚úÖ New best model! Val Acc=98.50%\n",
      "\n",
      "============================================================\n",
      "EPOCH 46/60\n",
      "============================================================\n",
      "Step=4499; Training Loss=0.2003\n",
      "\n",
      "üìä Epoch 45 Summary:\n",
      "   Train Loss: 0.2197\n",
      "   Val Acc: 98.50%\n",
      "   Val Loss: 0.0924\n",
      "   Learning Rate: 0.000364\n",
      "‚úÖ New best model! Val Acc=98.50%\n",
      "\n",
      "============================================================\n",
      "EPOCH 46/60\n",
      "============================================================\n",
      "Step=4599; Training Loss=0.2021\n",
      "\n",
      "üìä Epoch 46 Summary:\n",
      "   Train Loss: 0.2151\n",
      "   Val Acc: 97.50%\n",
      "   Val Loss: 0.0993\n",
      "   Learning Rate: 0.000346\n",
      "‚è≥ No improvement. Patience: 1/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 47/60\n",
      "============================================================\n",
      "Step=4599; Training Loss=0.2021\n",
      "\n",
      "üìä Epoch 46 Summary:\n",
      "   Train Loss: 0.2151\n",
      "   Val Acc: 97.50%\n",
      "   Val Loss: 0.0993\n",
      "   Learning Rate: 0.000346\n",
      "‚è≥ No improvement. Patience: 1/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 47/60\n",
      "============================================================\n",
      "Step=4699; Training Loss=0.2031\n",
      "\n",
      "üìä Epoch 47 Summary:\n",
      "   Train Loss: 0.2126\n",
      "   Val Acc: 98.50%\n",
      "   Val Loss: 0.0911\n",
      "   Learning Rate: 0.000327\n",
      "‚è≥ No improvement. Patience: 2/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 48/60\n",
      "============================================================\n",
      "Step=4699; Training Loss=0.2031\n",
      "\n",
      "üìä Epoch 47 Summary:\n",
      "   Train Loss: 0.2126\n",
      "   Val Acc: 98.50%\n",
      "   Val Loss: 0.0911\n",
      "   Learning Rate: 0.000327\n",
      "‚è≥ No improvement. Patience: 2/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 48/60\n",
      "============================================================\n",
      "Step=4799; Training Loss=0.2013\n",
      "\n",
      "üìä Epoch 48 Summary:\n",
      "   Train Loss: 0.2113\n",
      "   Val Acc: 98.00%\n",
      "   Val Loss: 0.0946\n",
      "   Learning Rate: 0.000308\n",
      "‚è≥ No improvement. Patience: 3/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 49/60\n",
      "============================================================\n",
      "Step=4799; Training Loss=0.2013\n",
      "\n",
      "üìä Epoch 48 Summary:\n",
      "   Train Loss: 0.2113\n",
      "   Val Acc: 98.00%\n",
      "   Val Loss: 0.0946\n",
      "   Learning Rate: 0.000308\n",
      "‚è≥ No improvement. Patience: 3/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 49/60\n",
      "============================================================\n",
      "Step=4899; Training Loss=0.2326\n",
      "\n",
      "üìä Epoch 49 Summary:\n",
      "   Train Loss: 0.2142\n",
      "   Val Acc: 98.50%\n",
      "   Val Loss: 0.0939\n",
      "   Learning Rate: 0.000289\n",
      "‚è≥ No improvement. Patience: 4/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 50/60\n",
      "============================================================\n",
      "Step=4899; Training Loss=0.2326\n",
      "\n",
      "üìä Epoch 49 Summary:\n",
      "   Train Loss: 0.2142\n",
      "   Val Acc: 98.50%\n",
      "   Val Loss: 0.0939\n",
      "   Learning Rate: 0.000289\n",
      "‚è≥ No improvement. Patience: 4/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 50/60\n",
      "============================================================\n",
      "Step=4999; Training Loss=0.2495\n",
      "\n",
      "üìä Epoch 50 Summary:\n",
      "   Train Loss: 0.2094\n",
      "   Val Acc: 98.00%\n",
      "   Val Loss: 0.0916\n",
      "   Learning Rate: 0.000270\n",
      "‚è≥ No improvement. Patience: 5/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 51/60\n",
      "============================================================\n",
      "Step=4999; Training Loss=0.2495\n",
      "\n",
      "üìä Epoch 50 Summary:\n",
      "   Train Loss: 0.2094\n",
      "   Val Acc: 98.00%\n",
      "   Val Loss: 0.0916\n",
      "   Learning Rate: 0.000270\n",
      "‚è≥ No improvement. Patience: 5/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 51/60\n",
      "============================================================\n",
      "Step=5099; Training Loss=0.2465\n",
      "\n",
      "üìä Epoch 51 Summary:\n",
      "   Train Loss: 0.2110\n",
      "   Val Acc: 98.00%\n",
      "   Val Loss: 0.0946\n",
      "   Learning Rate: 0.000250\n",
      "‚è≥ No improvement. Patience: 6/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 52/60\n",
      "============================================================\n",
      "Step=5099; Training Loss=0.2465\n",
      "\n",
      "üìä Epoch 51 Summary:\n",
      "   Train Loss: 0.2110\n",
      "   Val Acc: 98.00%\n",
      "   Val Loss: 0.0946\n",
      "   Learning Rate: 0.000250\n",
      "‚è≥ No improvement. Patience: 6/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 52/60\n",
      "============================================================\n",
      "Step=5199; Training Loss=0.2115\n",
      "\n",
      "üìä Epoch 52 Summary:\n",
      "   Train Loss: 0.2126\n",
      "   Val Acc: 97.50%\n",
      "   Val Loss: 0.0985\n",
      "   Learning Rate: 0.000230\n",
      "‚è≥ No improvement. Patience: 7/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 53/60\n",
      "============================================================\n",
      "Step=5199; Training Loss=0.2115\n",
      "\n",
      "üìä Epoch 52 Summary:\n",
      "   Train Loss: 0.2126\n",
      "   Val Acc: 97.50%\n",
      "   Val Loss: 0.0985\n",
      "   Learning Rate: 0.000230\n",
      "‚è≥ No improvement. Patience: 7/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 53/60\n",
      "============================================================\n",
      "Step=5299; Training Loss=0.2051\n",
      "\n",
      "üìä Epoch 53 Summary:\n",
      "   Train Loss: 0.2105\n",
      "   Val Acc: 98.00%\n",
      "   Val Loss: 0.0933\n",
      "   Learning Rate: 0.000211\n",
      "‚è≥ No improvement. Patience: 8/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 54/60\n",
      "============================================================\n",
      "Step=5299; Training Loss=0.2051\n",
      "\n",
      "üìä Epoch 53 Summary:\n",
      "   Train Loss: 0.2105\n",
      "   Val Acc: 98.00%\n",
      "   Val Loss: 0.0933\n",
      "   Learning Rate: 0.000211\n",
      "‚è≥ No improvement. Patience: 8/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 54/60\n",
      "============================================================\n",
      "Step=5399; Training Loss=0.2005\n",
      "\n",
      "üìä Epoch 54 Summary:\n",
      "   Train Loss: 0.2084\n",
      "   Val Acc: 97.00%\n",
      "   Val Loss: 0.1039\n",
      "   Learning Rate: 0.000192\n",
      "‚è≥ No improvement. Patience: 9/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 55/60\n",
      "============================================================\n",
      "Step=5399; Training Loss=0.2005\n",
      "\n",
      "üìä Epoch 54 Summary:\n",
      "   Train Loss: 0.2084\n",
      "   Val Acc: 97.00%\n",
      "   Val Loss: 0.1039\n",
      "   Learning Rate: 0.000192\n",
      "‚è≥ No improvement. Patience: 9/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 55/60\n",
      "============================================================\n",
      "Step=5499; Training Loss=0.2020\n",
      "\n",
      "üìä Epoch 55 Summary:\n",
      "   Train Loss: 0.2085\n",
      "   Val Acc: 98.50%\n",
      "   Val Loss: 0.0952\n",
      "   Learning Rate: 0.000173\n",
      "‚è≥ No improvement. Patience: 10/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 56/60\n",
      "============================================================\n",
      "Step=5499; Training Loss=0.2020\n",
      "\n",
      "üìä Epoch 55 Summary:\n",
      "   Train Loss: 0.2085\n",
      "   Val Acc: 98.50%\n",
      "   Val Loss: 0.0952\n",
      "   Learning Rate: 0.000173\n",
      "‚è≥ No improvement. Patience: 10/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 56/60\n",
      "============================================================\n",
      "Step=5599; Training Loss=0.2076\n",
      "\n",
      "üìä Epoch 56 Summary:\n",
      "   Train Loss: 0.2073\n",
      "   Val Acc: 98.00%\n",
      "   Val Loss: 0.0970\n",
      "   Learning Rate: 0.000154\n",
      "‚è≥ No improvement. Patience: 11/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 57/60\n",
      "============================================================\n",
      "Step=5599; Training Loss=0.2076\n",
      "\n",
      "üìä Epoch 56 Summary:\n",
      "   Train Loss: 0.2073\n",
      "   Val Acc: 98.00%\n",
      "   Val Loss: 0.0970\n",
      "   Learning Rate: 0.000154\n",
      "‚è≥ No improvement. Patience: 11/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 57/60\n",
      "============================================================\n",
      "Step=5699; Training Loss=0.2231\n",
      "\n",
      "üìä Epoch 57 Summary:\n",
      "   Train Loss: 0.2061\n",
      "   Val Acc: 98.50%\n",
      "   Val Loss: 0.0887\n",
      "   Learning Rate: 0.000137\n",
      "‚è≥ No improvement. Patience: 12/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 58/60\n",
      "============================================================\n",
      "Step=5699; Training Loss=0.2231\n",
      "\n",
      "üìä Epoch 57 Summary:\n",
      "   Train Loss: 0.2061\n",
      "   Val Acc: 98.50%\n",
      "   Val Loss: 0.0887\n",
      "   Learning Rate: 0.000137\n",
      "‚è≥ No improvement. Patience: 12/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 58/60\n",
      "============================================================\n",
      "Step=5799; Training Loss=0.1997\n",
      "\n",
      "üìä Epoch 58 Summary:\n",
      "   Train Loss: 0.2066\n",
      "   Val Acc: 98.00%\n",
      "   Val Loss: 0.0882\n",
      "   Learning Rate: 0.000119\n",
      "‚è≥ No improvement. Patience: 13/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 59/60\n",
      "============================================================\n",
      "Step=5799; Training Loss=0.1997\n",
      "\n",
      "üìä Epoch 58 Summary:\n",
      "   Train Loss: 0.2066\n",
      "   Val Acc: 98.00%\n",
      "   Val Loss: 0.0882\n",
      "   Learning Rate: 0.000119\n",
      "‚è≥ No improvement. Patience: 13/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 59/60\n",
      "============================================================\n",
      "Step=5899; Training Loss=0.2006\n",
      "\n",
      "üìä Epoch 59 Summary:\n",
      "   Train Loss: 0.2081\n",
      "   Val Acc: 98.00%\n",
      "   Val Loss: 0.0926\n",
      "   Learning Rate: 0.000103\n",
      "‚è≥ No improvement. Patience: 14/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 60/60\n",
      "============================================================\n",
      "Step=5899; Training Loss=0.2006\n",
      "\n",
      "üìä Epoch 59 Summary:\n",
      "   Train Loss: 0.2081\n",
      "   Val Acc: 98.00%\n",
      "   Val Loss: 0.0926\n",
      "   Learning Rate: 0.000103\n",
      "‚è≥ No improvement. Patience: 14/20\n",
      "\n",
      "============================================================\n",
      "EPOCH 60/60\n",
      "============================================================\n",
      "Step=5999; Training Loss=0.2271\n",
      "\n",
      "üìä Epoch 60 Summary:\n",
      "   Train Loss: 0.2089\n",
      "   Val Acc: 97.50%\n",
      "   Val Loss: 0.0955\n",
      "   Learning Rate: 0.000088\n",
      "‚è≥ No improvement. Patience: 15/20\n",
      "\n",
      "‚úÖ Loaded best model with Val Acc=98.50%\n",
      "\n",
      "============================================================\n",
      "Training completed after 60 epochs\n",
      "Best validation accuracy: 98.50%\n",
      "============================================================\n",
      "Step=5999; Training Loss=0.2271\n",
      "\n",
      "üìä Epoch 60 Summary:\n",
      "   Train Loss: 0.2089\n",
      "   Val Acc: 97.50%\n",
      "   Val Loss: 0.0955\n",
      "   Learning Rate: 0.000088\n",
      "‚è≥ No improvement. Patience: 15/20\n",
      "\n",
      "‚úÖ Loaded best model with Val Acc=98.50%\n",
      "\n",
      "============================================================\n",
      "Training completed after 60 epochs\n",
      "Best validation accuracy: 98.50%\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================== TRAINING LOOP ====================\n",
    "print(\"\\nüöÄ Starting training...\")\n",
    "\n",
    "steps_per_epoch = len(train_loader) // CFG['epochs']\n",
    "current_epoch = 0\n",
    "train_history = {'epoch': [], 'train_loss': [], 'val_acc': [], 'val_loss': [], 'lr': []}\n",
    "\n",
    "for epoch in range(CFG['epochs']):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"EPOCH {epoch+1}/{CFG['epochs']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    train_loss = train_epoch(\n",
    "        model, feature_extractor, train_loader, optimizer, loss_module, \n",
    "        DEVICE, steps_per_epoch, epoch, train_augmentation\n",
    "    )\n",
    "    \n",
    "    current_epoch += 1\n",
    "    val_acc, val_loss = evaluate(model, feature_extractor, val_loader, DEVICE)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    print(f'\\nüìä Epoch {current_epoch} Summary:')\n",
    "    print(f'   Train Loss: {train_loss:.4f}')\n",
    "    print(f'   Val Acc: {val_acc:.2f}%')\n",
    "    print(f'   Val Loss: {val_loss:.4f}')\n",
    "    print(f'   Learning Rate: {current_lr:.6f}')\n",
    "    \n",
    "    train_history['epoch'].append(current_epoch)\n",
    "    train_history['train_loss'].append(train_loss)\n",
    "    train_history['val_acc'].append(val_acc)\n",
    "    train_history['val_loss'].append(val_loss)\n",
    "    train_history['lr'].append(current_lr)\n",
    "    \n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_val_loss = val_loss\n",
    "        best_model_state = model.state_dict().copy()\n",
    "        patience_counter = 0\n",
    "        print(f'‚úÖ New best model! Val Acc={val_acc:.2f}%')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f'‚è≥ No improvement. Patience: {patience_counter}/{patience}')\n",
    "    \n",
    "    if patience_counter >= patience:\n",
    "        print(f'\\nüõë Early stopping at epoch {current_epoch}')\n",
    "        break\n",
    "    \n",
    "    scheduler.step()\n",
    "\n",
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(f'\\n‚úÖ Loaded best model with Val Acc={best_val_acc:.2f}%')\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Training completed after {current_epoch} epochs\")\n",
    "print(f\"Best validation accuracy: {best_val_acc:.2f}%\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Evaluating model on test set...\n",
      "\n",
      "üéØ Test Accuracy: 99.50%\n",
      "‚úÖ PASSED: Accuracy > 99.4%\n"
     ]
    }
   ],
   "source": [
    "# ==================== TEST EVALUATION ====================\n",
    "print(\"\\nüìä Evaluating model on test set...\")\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "feature_extractor = feature_extractor.to(DEVICE)\n",
    "\n",
    "test_accuracy = test_model(model, feature_extractor, test_loader, DEVICE)\n",
    "print(f'\\nüéØ Test Accuracy: {test_accuracy:.2f}%')\n",
    "\n",
    "if test_accuracy > 99.4:\n",
    "    print(\"‚úÖ PASSED: Accuracy > 99.4%\")\n",
    "else:\n",
    "    print(\"‚ùå FAILED: Accuracy <= 99.4%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": "99a6df57d92146afae7054ec23e004f7",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SAVING MODEL\n",
      "============================================================\n",
      "Model Timestamp: 1764424228\n",
      "\n",
      "üîÑ Moving models to CPU for ONNX export...\n",
      "\n",
      "üì¶ Exporting Feature Extractor to ONNX...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1129 14:50:29.259000 49064 torch/onnx/_internal/exporter/_registration.py:107] torchvision is not installed. Skipping torchvision::nms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `MelSpectrogramExtractor([...]` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `MelSpectrogramExtractor([...]` with `torch.export.export(..., strict=False)`... ‚úÖ\n",
      "[torch.onnx] Run decomposition...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1129 14:50:29.664000 49064 torch/onnx/_internal/exporter/_registration.py:107] torchvision is not installed. Skipping torchvision::nms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Run decomposition... ‚úÖ\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ‚úÖ\n",
      "Applied 4 of general pattern rewrite rules.\n",
      "‚úÖ Feature extractor saved: ./saved_models//1764424228_frontend.onnx\n",
      "\n",
      "üì¶ Exporting Model to ONNX...\n",
      "[torch.onnx] Obtain model graph for `KeywordSpotterV2([...]` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `KeywordSpotterV2([...]` with `torch.export.export(..., strict=False)`... ‚úÖ\n",
      "[torch.onnx] Run decomposition...\n",
      "[torch.onnx] Run decomposition... ‚úÖ\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ‚úÖ\n",
      "Applied 16 of general pattern rewrite rules.\n",
      "‚úÖ Model saved: ./saved_models//1764424228_model.onnx\n",
      "\n",
      "============================================================\n",
      "SIZE REPORT (ONNX - Float32)\n",
      "============================================================\n",
      "Feature Extractor: 332.22 KB\n",
      "Model: 3057.24 KB\n",
      "Total: 3389.46 KB\n",
      "‚ö†Ô∏è  WARNING: Size > 300 KB - quantization required!\n",
      "\n",
      "üìù Saving results...\n",
      "‚úÖ Results saved to ./keyword_spotter_results.csv\n",
      "\n",
      "============================================================\n",
      "TRAINING COMPLETE\n",
      "============================================================\n",
      "[torch.onnx] Obtain model graph for `KeywordSpotterV2([...]` with `torch.export.export(..., strict=False)`... ‚úÖ\n",
      "[torch.onnx] Run decomposition...\n",
      "[torch.onnx] Run decomposition... ‚úÖ\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ‚úÖ\n",
      "Applied 16 of general pattern rewrite rules.\n",
      "‚úÖ Model saved: ./saved_models//1764424228_model.onnx\n",
      "\n",
      "============================================================\n",
      "SIZE REPORT (ONNX - Float32)\n",
      "============================================================\n",
      "Feature Extractor: 332.22 KB\n",
      "Model: 3057.24 KB\n",
      "Total: 3389.46 KB\n",
      "‚ö†Ô∏è  WARNING: Size > 300 KB - quantization required!\n",
      "\n",
      "üìù Saving results...\n",
      "‚úÖ Results saved to ./keyword_spotter_results.csv\n",
      "\n",
      "============================================================\n",
      "TRAINING COMPLETE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================== SAVE MODEL ====================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SAVING MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "timestamp = int(time())\n",
    "saved_model_dir = './saved_models/'\n",
    "if not os.path.exists(saved_model_dir):\n",
    "    os.makedirs(saved_model_dir)\n",
    "\n",
    "print(f'Model Timestamp: {timestamp}')\n",
    "\n",
    "model.eval()\n",
    "feature_extractor.eval()\n",
    "\n",
    "print(\"\\nüîÑ Moving models to CPU for ONNX export...\")\n",
    "model_cpu = model.cpu()\n",
    "feature_extractor_cpu = feature_extractor.cpu()\n",
    "\n",
    "print(\"\\nüì¶ Exporting Feature Extractor to ONNX...\")\n",
    "torch.onnx.export(\n",
    "    feature_extractor_cpu,\n",
    "    torch.randn(1, 16000),\n",
    "    f'{saved_model_dir}/{timestamp}_frontend.onnx',\n",
    "    input_names=['input'],\n",
    "    dynamo=True,\n",
    "    optimize=True,\n",
    "    report=False,\n",
    "    external_data=False,\n",
    ")\n",
    "print(f\"‚úÖ Feature extractor saved: {saved_model_dir}/{timestamp}_frontend.onnx\")\n",
    "\n",
    "print(\"\\nüì¶ Exporting Model to ONNX...\")\n",
    "sample_waveform = train_dataset[0]['x'].squeeze(0).unsqueeze(0).cpu()\n",
    "sample_features = feature_extractor_cpu(sample_waveform)\n",
    "torch.onnx.export(\n",
    "    model_cpu,\n",
    "    sample_features,\n",
    "    f'{saved_model_dir}/{timestamp}_model.onnx',\n",
    "    input_names=['input'],\n",
    "    dynamo=True,\n",
    "    optimize=True,\n",
    "    report=False,\n",
    "    external_data=False,\n",
    ")\n",
    "print(f\"‚úÖ Model saved: {saved_model_dir}/{timestamp}_model.onnx\")\n",
    "\n",
    "fe_size = os.path.getsize(f'{saved_model_dir}/{timestamp}_frontend.onnx') / 1024\n",
    "model_size = os.path.getsize(f'{saved_model_dir}/{timestamp}_model.onnx') / 1024\n",
    "total_size = fe_size + model_size\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SIZE REPORT (ONNX - Float32)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Feature Extractor: {fe_size:.2f} KB\")\n",
    "print(f\"Model: {model_size:.2f} KB\")\n",
    "print(f\"Total: {total_size:.2f} KB\")\n",
    "\n",
    "if total_size < 300:\n",
    "    print(\"‚úÖ PASSED: Total size < 300 KB (before quantization)\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  WARNING: Size > 300 KB - quantization required!\")\n",
    "\n",
    "print(\"\\nüìù Saving results...\")\n",
    "output_dict = {\n",
    "    'timestamp': timestamp,\n",
    "    **CFG,\n",
    "    'test_accuracy': test_accuracy\n",
    "}\n",
    "\n",
    "df = pd.DataFrame([output_dict])\n",
    "output_path = './keyword_spotter_results.csv'\n",
    "df.to_csv(output_path, mode='a', header=not os.path.exists(output_path), index=False)\n",
    "print(f\"‚úÖ Results saved to {output_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(\"=\"*60)\n"
   ]
  }
 ],
 "metadata": {
  "deepnote_notebook_id": "c0fbadf4c9c044908423f738834a5ee0",
  "kernelspec": {
   "display_name": "hw2-Xe6H3gEB-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
