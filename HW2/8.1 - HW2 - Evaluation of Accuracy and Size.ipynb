{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c6bfcce0080c49a9aeab2b39ab7a0eb9",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# Homework 2: ONNX Accuracy & Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "b439e5cd32a24dbe84df400d224f8246",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Import the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "f2365c330c5d4df38e4bb146c666af1f",
    "deepnote_cell_type": "code",
    "execution_context_id": "74a68beb-192b-4524-b735-d639d6ac6210",
    "execution_millis": 1350,
    "execution_start": 1764251417817,
    "source_hash": "591f6440"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "from msc_dataset import MSCDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a6c765d6afcc426fb5402efd97086f4a",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Create the Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "3855e2030ac14f7a9151b28bd8527aaf",
    "deepnote_cell_type": "code",
    "execution_context_id": "74a68beb-192b-4524-b735-d639d6ac6210",
    "execution_millis": 0,
    "execution_start": 1764251419230,
    "source_hash": "6cf3e807"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data folder: ./msc-testing\n",
      "Loaded 200 samples from ./msc-testing for classes ['stop', 'up']\n",
      "Test dataset size: 200\n"
     ]
    }
   ],
   "source": [
    "CLASSES = ['stop', 'up']\n",
    "\n",
    "test_ds = MSCDataset(\n",
    "    root='.',\n",
    "    classes=CLASSES,\n",
    "    split='testing',\n",
    "    preprocess=None\n",
    ")\n",
    "print(f\"Test dataset size: {len(test_ds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "dbf86c4656a4482889758dbade2781c2",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Set ONNX files name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "278df9240a1845c29887bffb6a1599a3",
    "deepnote_cell_type": "code",
    "execution_context_id": "74a68beb-192b-4524-b735-d639d6ac6210",
    "execution_millis": 0,
    "execution_start": 1764251419290,
    "source_hash": "57cadf06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using models:\n",
      "  Frontend: ./saved_models/1764339634_frontend.onnx\n",
      "  Model: ./saved_models/1764339634_model.onnx\n"
     ]
    }
   ],
   "source": [
    "# Trova automaticamente l'ultimo modello salvato\n",
    "import glob\n",
    "\n",
    "saved_models_dir = './saved_models/'\n",
    "frontend_files = sorted(glob.glob(f'{saved_models_dir}*_frontend.onnx'))\n",
    "model_files = sorted(glob.glob(f'{saved_models_dir}*_model.onnx'))\n",
    "\n",
    "if not frontend_files or not model_files:\n",
    "    raise FileNotFoundError(\"No ONNX models found in ./saved_models/\")\n",
    "\n",
    "# Prendi l'ultimo (ordinato per timestamp nel nome)\n",
    "frontend_file = frontend_files[-1]\n",
    "model_file = model_files[-1]\n",
    "\n",
    "print(f\"Using models:\")\n",
    "print(f\"  Frontend: {frontend_file}\")\n",
    "print(f\"  Model: {model_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "6df8d1aea751424aaa9eeeb849bc8d59",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Unzip the ONNX model, if .zip is provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "764c4f4b536a436fba1b08e587865b46",
    "deepnote_cell_type": "code",
    "execution_context_id": "74a68beb-192b-4524-b735-d639d6ac6210",
    "execution_millis": 417,
    "execution_start": 1764251419340,
    "source_hash": "d0014f26"
   },
   "outputs": [],
   "source": [
    "if model_file.lower().endswith(\".zip\"):\n",
    "    with zipfile.ZipFile(model_file, \"r\") as z:\n",
    "        # The only file inside the ZIP\n",
    "        onnx_model_file = z.namelist()[0]\n",
    "        z.extract(onnx_model_file, \".\")   # extract into current directory\n",
    "else:\n",
    "    onnx_model_file = model_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "55558fa36a5e420690ee8481ce75cc23",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Evaluate the ONNX Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "dfa243c078054a968fd494ab714fdd67",
    "deepnote_cell_type": "code",
    "execution_context_id": "74a68beb-192b-4524-b735-d639d6ac6210",
    "execution_millis": 8220,
    "execution_start": 1764251420000,
    "source_hash": "6cdabb62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ Accuracy: 90.00%\n",
      "ðŸ“¦ Feature Extraction Size: 332.5KB\n",
      "ðŸ“¦ Model Size: 1022.7KB\n",
      "ðŸ“¦ Total Size: 1355.2KB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ort_frontend = ort.InferenceSession(frontend_file)\n",
    "ort_model = ort.InferenceSession(onnx_model_file)\n",
    "\n",
    "true_count = 0.0\n",
    "for sample in test_ds:\n",
    "    inputs = sample['x']\n",
    "    label = sample['y']  # Changed from 'label' to 'y'\n",
    "    inputs = inputs.squeeze(0).numpy()  # Remove channel dimension first\n",
    "    inputs = np.expand_dims(inputs, 0)  # Add batch dimension\n",
    "    features = ort_frontend.run(None, {'input': inputs})[0]\n",
    "    outputs = ort_model.run(None,  {'input': features})[0]\n",
    "    prediction = np.argmax(outputs, axis=-1).item()\n",
    "    true_count += prediction == label\n",
    "\n",
    "accuracy = true_count / len(test_ds) * 100\n",
    "frontend_size = os.path.getsize(frontend_file)\n",
    "model_size = os.path.getsize(model_file)\n",
    "total_size = frontend_size + model_size\n",
    "\n",
    "print(f'ðŸŽ¯ ONNX Accuracy: {accuracy:.2f}%')\n",
    "print(f'ðŸ“¦ Feature Extraction Size: {frontend_size / 2**10:.1f}KB')\n",
    "print(f'ðŸ“¦ Model Size: {model_size / 2**10:.1f}KB')\n",
    "print(f'ðŸ“¦ Total Size: {total_size / 2**10:.1f}KB')"
   ]
  }
 ],
 "metadata": {
  "deepnote_notebook_id": "6e5359ec36e44072a6f7f21b245f5b6f",
  "kernelspec": {
   "display_name": "hw2-Xe6H3gEB-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
