{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1a9f912a6dc5431580a3a9fb6498443f",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# Training with DS-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1b35f9c74432491185fc5c20c5b1ed52",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Import the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "25fa8088964f4bdab30180a61abb2cf0",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "from time import time\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from msc_dataset_lab4 import MSCDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "91ee69744eef4b2f81d6b956534fe010",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Define the Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "f7069abc0964477789b9a15f9f4f7cfb",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'sampling_rate': 16000,\n",
    "    'frame_length_in_s': 0.04,\n",
    "    'frame_step_in_s': 0.02,\n",
    "    'n_mels': 40,\n",
    "    'f_min': 0,\n",
    "    'f_max': 8000,\n",
    "    'n_mfcc': 40,\n",
    "    'seed': 0,\n",
    "    'train_steps': 2000,\n",
    "    'train_batch_size': 32,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "76b81dc21ebc4f3094860b8b3624c0f8",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Define the target classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "134d63bb3042407eaf47d102320c8160",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# Define the set of target classes\n",
    "CLASSES = ['start', 'stop', 'other']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "823b1d18daf747ff954ccd08dde2ee27",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Set Deterministic Behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "aca3e7522dd04b1d815521c54d75d8a4",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(CFG['seed'])\n",
    "np.random.seed(CFG['seed'])\n",
    "random.seed(CFG['seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "61436e40b83046808ce5b4b705577d16",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Create Datasets and Dataloaders for train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "bfa10797e1f74b4e9d6fbe38ac852fd0",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "transform = T.MFCC(\n",
    "    sample_rate=16000,\n",
    "    n_mfcc=CFG['n_mfcc'],\n",
    "    log_mels=True,\n",
    "    melkwargs=dict(\n",
    "        # Spectrogram parameters\n",
    "        n_fft=int(CFG['frame_length_in_s'] * CFG['sampling_rate']),\n",
    "        win_length=int(CFG['frame_length_in_s'] * CFG['sampling_rate']),\n",
    "        hop_length=int(CFG['frame_step_in_s'] * CFG['sampling_rate']),\n",
    "        center=False,\n",
    "        # Mel Spectrogram paramaters\n",
    "        f_min=CFG['f_min'],\n",
    "        f_max=CFG['f_max'],\n",
    "        n_mels=CFG['n_mels'],\n",
    "    )\n",
    ")\n",
    "\n",
    "# Instantiate train_ds and test_ds objects\n",
    "train_ds = MSCDataset(\n",
    "    root='.',\n",
    "    classes=CLASSES,\n",
    "    split='training',\n",
    "    preprocess=transform,\n",
    "    download=True,\n",
    ")\n",
    "\n",
    "test_ds = MSCDataset(\n",
    "    root='.',\n",
    "    classes=CLASSES,\n",
    "    split='testing',\n",
    "    preprocess=transform,\n",
    "    download=True,\n",
    ")\n",
    "\n",
    "sampler = torch.utils.data.RandomSampler(\n",
    "    train_ds,\n",
    "    replacement=True,\n",
    "    num_samples=CFG['train_steps'] * CFG['train_batch_size'],\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=CFG['train_batch_size'],\n",
    "    sampler=sampler,\n",
    "    num_workers=2,\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_ds, batch_size=100, num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "291b216649b84fa990d5bed174780671",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Create the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "9ffc8f7a50734c9987027266ca34ac53",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# DS-CNN Model with Depthwise Separable Convolutions\n",
    "class DSCNN(nn.Module):\n",
    "    def __init__(self, num_classes=8):\n",
    "        super(DSCNN, self).__init__()\n",
    "        \n",
    "        # Initial 2D Conv\n",
    "        self.conv1 = nn.Conv2d(1, 128, kernel_size=3, stride=2, padding=0, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(128)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        # First DS Block: DConv + SConv\n",
    "        self.dconv1 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, groups=128, bias=False)  # Depthwise\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.sconv1 = nn.Conv2d(128, 128, kernel_size=1, stride=1, padding=0, bias=False)  # Separable (pointwise)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        # Second DS Block: DConv + SConv\n",
    "        self.dconv2 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, groups=128, bias=False)  # Depthwise\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.sconv2 = nn.Conv2d(128, 128, kernel_size=1, stride=1, padding=0, bias=False)  # Separable (pointwise)\n",
    "        self.bn5 = nn.BatchNorm2d(128)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        \n",
    "        # Global Average Pooling\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        # Linear classifier\n",
    "        self.fc = nn.Linear(128, num_classes, bias=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Initial Conv block\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        \n",
    "        # First DS block\n",
    "        x = self.dconv1(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.sconv1(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu3(x)\n",
    "        \n",
    "        # Second DS block\n",
    "        x = self.dconv2(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.sconv2(x)\n",
    "        x = self.bn5(x)\n",
    "        x = self.relu5(x)\n",
    "        \n",
    "        # GAP and classifier\n",
    "        x = self.gap(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = DSCNN(num_classes=len(CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "c45580dad7094259a1d40d3e97895955",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "57cea235cdfc4187a99ec58161704178",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Define the Training Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "171ede021e1743f89c406db34efd68d7",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# Instantiate the loss and optimizer objects\n",
    "loss_module = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "ff8eff57dfa6457cafb0e53eac0a96df",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Define the Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "cc340b64b6964232bd061b21dd9a7dfd",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "model.train()\n",
    "\n",
    "for step, batch in enumerate(train_loader):\n",
    "    x = batch['x']\n",
    "    y = batch['y']\n",
    "    \n",
    "    # Forward pass\n",
    "    output = model(x)\n",
    "    loss = loss_module(output, y)\n",
    "    \n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if ((step + 1) % 100) == 0 or step == 0:\n",
    "        print(f'Step={step}; Training Loss={loss.item():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4ef68f6d3aa14779a5494520a323b311",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "f1e90f19b549408aaef02562d4c41067",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 93.25%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation loop\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        x = batch['x']\n",
    "        y = batch['y']\n",
    "        \n",
    "        output = model(x)\n",
    "        predictions = output.argmax(dim=1)\n",
    "        \n",
    "        correct += (predictions == y).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "test_accuracy = (correct / total) * 100\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "3cc47f88a96048f1b22583719a4fd901",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "30a2a772f2e446708b8e34c70258134e",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "timestamp = int(time())\n",
    "\n",
    "saved_model_dir = './saved_models/'\n",
    "if not os.path.exists(saved_model_dir):\n",
    "    os.makedirs(saved_model_dir)\n",
    "\n",
    "print(f'Model Timestamp: {timestamp}')\n",
    "\n",
    "torch.onnx.export(\n",
    "    transform,  # model to export\n",
    "    torch.randn(1, 1, 16000),  # inputs of the model,\n",
    "    f'{saved_model_dir}/{timestamp}_frontend.onnx',  # filename of the ONNX model\n",
    "    input_names=['input'], # input name in the ONNX model\n",
    "    dynamo=True,\n",
    "    optimize=True,\n",
    "    report=False,\n",
    "    external_data=False,\n",
    ")\n",
    "torch.onnx.export(\n",
    "    model,  # model to export\n",
    "    train_ds[0]['x'].unsqueeze(0),  # inputs of the model,\n",
    "    f'{saved_model_dir}/{timestamp}_model.onnx',  # filename of the ONNX model\n",
    "    input_names=['input'], # input name in the ONNX model\n",
    "    dynamo=True,\n",
    "    optimize=True,\n",
    "    report=False,\n",
    "    external_data=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "dc0f4532a1e74d6db2f67af694caeab2",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Save Hyperparameters & Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": "69699ff1829a4125a4d6f98c0a053c1d",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "output_dict = {\n",
    "    'timestamp': timestamp,\n",
    "    **CFG,\n",
    "    'test_accuracy': test_accuracy\n",
    "}\n",
    "\n",
    "df = pd.DataFrame([output_dict])\n",
    "\n",
    "output_path='./dscnn_results.csv'\n",
    "df.to_csv(output_path, mode='a', header=not os.path.exists(output_path), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=3880e510-b64c-4bb5-b488-c2122d5d9e2d' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote_notebook_id": "6272d8b9a70648f0a9ef668d6ec447df",
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
