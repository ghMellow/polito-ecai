{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"99ea6d1423024b918314d8dee1f413ae","deepnote_cell_type":"markdown"},"source":"# Post-Training Quantization","block_group":"1c74c1c9f7ee4622b1a4773059d09029"},{"cell_type":"markdown","metadata":{"cell_id":"917da8beb31a40ee8f1a23b9217c1169","deepnote_cell_type":"markdown"},"source":"## Import the required modules","block_group":"c29c4de5766e4359a66a1ad13464c4f5"},{"cell_type":"code","metadata":{"cell_id":"ccb26be73679493bbdb97807e59bd6c7","deepnote_cell_type":"code"},"source":"import numpy as np\nimport onnx\nimport onnxruntime as ort\nimport os\nimport random\nimport torch\n\nfrom onnxruntime.quantization import (\n    CalibrationDataReader,\n    CalibrationMethod,\n    QuantFormat,\n    QuantType,\n    StaticQuantConfig,\n    quantize,\n)\n\nfrom msc_dataset_lab3 import MSCDataset","block_group":"70e2b3a38dff46509027ccfcce081843","execution_count":1,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"e9b54af2f6234b67b9eac2622bfa05b0","deepnote_cell_type":"markdown"},"source":"## Set Deterministic Behaviour","block_group":"76300aa1a83941f5aaf217ed8e28ed53"},{"cell_type":"code","metadata":{"cell_id":"c542ba15743c447eb1b141bb818150e1","deepnote_cell_type":"code"},"source":"torch.manual_seed(0)\nnp.random.seed(0)\nrandom.seed(0)","block_group":"296e278a1bee48dca87174b35ec310d3","execution_count":2,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"922e474df3c541b8a3ec316b003954f9","deepnote_cell_type":"markdown"},"source":"## Create Datasets for Calibration/Test","block_group":"479b4ffcc72b416b93f2028dca3bd99b"},{"cell_type":"code","metadata":{"cell_id":"990310c284524fb597afed218e0f8dc5","deepnote_cell_type":"code"},"source":"CLASSES = ['stop', 'up']\n\ncalibration_ds = MSCDataset('/tmp/msc-val', torch.nn.Identity(), CLASSES)\ntest_ds = MSCDataset('/tmp/msc-test', torch.nn.Identity(), CLASSES)","block_group":"fcf034813bad49d791264880f9fba232","execution_count":3,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"e5a3536804b94ae4b0420780fff2f80d","deepnote_cell_type":"markdown"},"source":"## Define the Model Name","block_group":"0a079e62fb114864966f650cee68c0bf"},{"cell_type":"code","metadata":{"cell_id":"ee2dd94ae0fa422b94ca00bac6da06aa","deepnote_cell_type":"code"},"source":"MODEL_NAME = '1753860010'","block_group":"8abbd32b6b0b466bb84a5b76cc7f055e","execution_count":4,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"7333d4aef0aa4c4fa81bb13aec583c58","deepnote_cell_type":"markdown"},"source":"## Evaluate the Float32 ONNX Model","block_group":"8e6eccfb4dd547a0967b02567a3c608e"},{"cell_type":"code","metadata":{"cell_id":"f27b9d24c534458db6ce8f1be2b3d548","deepnote_cell_type":"code"},"source":"frontend_float32_file = f'./saved_models/{MODEL_NAME}_frontend.onnx'\nmodel_float32_file = f'./saved_models/{MODEL_NAME}_model.onnx'\nort_frontend = ort.InferenceSession(frontend_float32_file)\nort_model = ort.InferenceSession(model_float32_file)\n\ntrue_count = 0.0\nfor sample in test_ds:\n    inputs = sample['x']\n    label = sample['label']\n    inputs = inputs.numpy()\n    inputs = np.expand_dims(inputs, 0)\n    features = ort_frontend.run(None, {'input': inputs})[0]\n    outputs = ort_model.run(None,  {'input': features})[0]\n    prediction = np.argmax(outputs, axis=-1).item()\n    true_count += prediction == label\n\nfloat32_accuracy = true_count / len(test_ds) * 100\nfrontend_size = os.path.getsize(frontend_float32_file)\nmodel_float32_size = os.path.getsize(model_float32_file)\ntotal_float32_size = frontend_size + model_float32_size\n\nprint(f'Float32 Accuracy: {float32_accuracy:.2f}%')\nprint(f'Float32 Frontend Size: {frontend_size / 2**10:.1f}KB')\nprint(f'Float32 Model Size: {model_float32_size / 2**10:.1f}KB')\nprint(f'Float32 Total Size: {total_float32_size / 2**10:.1f}KB')\n","block_group":"a10c2795f90747fcb8e18bb310231fb7","execution_count":5,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"08731eb157674f229f1a2d7de185049e","deepnote_cell_type":"markdown"},"source":"## Create the Calibration Class","block_group":"30af41e3f3ec4dcbb6753ddb51510bcf"},{"cell_type":"code","metadata":{"cell_id":"11b0101a5c09494aa13fa753a10724ce","deepnote_cell_type":"code"},"source":"class DataReader(CalibrationDataReader):\n    def __init__(self, dataset):\n        self.dataset = dataset\n        self.enum_data = None\n\n        self.datasize = len(self.dataset)\n\n    def get_next(self):\n        if self.enum_data is None:\n            self.enum_data = iter(self.dataset)\n\n        x = next(self.enum_data, None)\n\n        if x is None:\n            return None\n\n        x = x['x']\n        x = x.numpy()\n        x = np.expand_dims(x, 0)\n        x = ort_frontend.run(None, {'input': x})[0]\n        x = {'input': x}\n\n        return x\n\n    def rewind(self):\n        self.enum_data = None\n\n\ndata_reader = DataReader(calibration_ds)","block_group":"c28042fc016340c4be8b9c5d4337af61","execution_count":6,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"ab3fa32cb2954c15bb1e5ffd0356cfa1","deepnote_cell_type":"markdown"},"source":"## Quantize the Model to INT8","block_group":"9140e01a5b03473b9b39fc270301052b"},{"cell_type":"code","metadata":{"cell_id":"ad74ce7da8344beba09b79973b4b475d","deepnote_cell_type":"code"},"source":"conf = StaticQuantConfig(\n    calibration_data_reader=data_reader,\n    quant_format=QuantFormat.QDQ,\n    calibrate_method=CalibrationMethod.MinMax ,\n    activation_type=QuantType.QInt8,\n    weight_type=QuantType.QInt8,\n    per_channel=False,\n)\n\nmodel_int8_file = f'./saved_models/{MODEL_NAME}_INT8.onnx'\nquantize(model_float32_file, model_int8_file, conf)","block_group":"e41f18a40f8849e290c5bba6ea2176b9","execution_count":7,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"ef37b3f58731426cbb281e717159a420","deepnote_cell_type":"markdown"},"source":"## Evaluate the INT8 Model","block_group":"ca59b97917ff4dcd8d0d21c051d446af"},{"cell_type":"code","metadata":{"cell_id":"7c307c1daadd41eaaa5e2fbcd4f7acd5","deepnote_cell_type":"code"},"source":"ort_model_int8 = ort.InferenceSession(model_int8_file)\n\ntrue_quant_count = 0.0\nfor sample in test_ds:\n    inputs = sample['x']\n    label = sample['label']\n    inputs = inputs.numpy()\n    inputs = np.expand_dims(inputs, 0)\n    features = ort_frontend.run(None, {'input': inputs})[0]\n    outputs = ort_model_int8.run(None,  {'input': features})[0]\n    prediction = np.argmax(outputs, axis=-1).item()\n    true_quant_count += prediction == label\n\nint8_accuracy = true_quant_count / len(test_ds) * 100\nfrontend_size = os.path.getsize(frontend_float32_file)\nmodel_int8_size = os.path.getsize(model_int8_file)\ntotal_int8_size = frontend_size + model_int8_size\n\nprint(f'INT8 Accuracy: {int8_accuracy:.2f}%')\nprint(f'Float32 Frontend Size: {frontend_size / 2**10:.1f}KB')\nprint(f'INT8 Model Size: {model_int8_size / 2**10:.1f}KB')\nprint(f'INT8 Total Size: {total_int8_size / 2**10:.1f}KB')","block_group":"049299d9076a4d8e9af892dc9524445f","execution_count":8,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=3880e510-b64c-4bb5-b488-c2122d5d9e2d' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_notebook_id":"68d71019031047c89ef21285079c67b7"}}